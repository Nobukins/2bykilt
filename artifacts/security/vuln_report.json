{
  "metadata": {
    "tool": "pip-audit",
    "version": "unknown",
    "generated_at": "2025-09-08T08:34:26.833163+00:00",
    "total_vulnerabilities": 9,
    "suppressed_count": 2,
    "scan_target": "python-dependencies"
  },
  "vulnerabilities": [
    {
      "id": "GHSA-2c2j-9gv5-cj73",
      "package": "starlette",
      "version": "0.46.1",
      "severity": "unknown",
      "description": "### Summary When parsing a multi-part form with large files (greater than the [default max spool size](https://github.com/encode/starlette/blob/fa5355442753f794965ae1af0f87f9fec1b9a3de/starlette/formparsers.py#L126)) `starlette` will block the main thread to roll the file over to disk. This blocks the event thread which means we can't accept new connections.  ### Details Please see this discussion for details: https://github.com/encode/starlette/discussions/2927#discussioncomment-13721403. In summary the following UploadFile code (copied from [here](https://github.com/encode/starlette/blob/fa5355442753f794965ae1af0f87f9fec1b9a3de/starlette/datastructures.py#L436C5-L447C14)) has a minor bug. Instead of just checking for `self._in_memory` we should also check if the additional bytes will cause a rollover.  ```python      @property     def _in_memory(self) -> bool:         # check for SpooledTemporaryFile._rolled         rolled_to_disk = getattr(self.file, \"_rolled\", True)         return not rolled_to_disk      async def write(self, data: bytes) -> None:         if self.size is not None:             self.size += len(data)          if self._in_memory:             self.file.write(data)         else:             await run_in_threadpool(self.file.write, data) ```  I have already created a PR which fixes the problem: https://github.com/encode/starlette/pull/2962   ### PoC See the discussion [here](https://github.com/encode/starlette/discussions/2927#discussioncomment-13721403) for steps on how to reproduce.  ### Impact To be honest, very low and not many users will be impacted. Parsing large forms is already CPU intensive so the additional IO block doesn't slow down `starlette` that much on systems with modern HDDs/SSDs. If someone is running on tape they might see a greater impact.",
      "cve": "CVE-2025-54121",
      "urls": [],
      "fix_available": true,
      "fix_version": "0.47.2",
      "source": "pip-audit"
    },
    {
      "id": "GHSA-j2jg-fq62-7c3h",
      "package": "gradio",
      "version": "5.10.0",
      "severity": "unknown",
      "description": "## Summary  Gradio's Access Control List (ACL) for file paths can be bypassed by altering the letter case of a blocked file or directory path. This vulnerability arises due to the lack of case normalization in the file path validation logic. On case-insensitive file systems, such as those used by Windows and macOS, this flaw enables attackers to circumvent security restrictions and access sensitive files that should be protected.  This issue can lead to unauthorized data access, exposing sensitive information and undermining the integrity of Gradio's security model. Given Gradio's popularity for building web applications, particularly in machine learning and AI, this vulnerability may pose a substantial threat if exploited in production environments.  ## Affected Version  Gradio <= 5.6.0  ## Impact  - **Unauthorized Access**: Sensitive files or directories specified in `blocked_paths` can be accessed by attackers.  - **Data Exposure**: Critical files, such as configuration files or user data, may be leaked.  - **Security Breach**: This can lead to broader application or system compromise if sensitive files contain credentials or API keys.  ## Root Cause  The [`blocked_paths`](https://github.com/gradio-app/gradio/blob/main/gradio/blocks.py#L2310) parameter in Gradio block's initial configuration is designed to restrict user access to specific files or directories in the local file system. However, it does not account for case-insensitive operating systems, such as Windows and macOS. This oversight enables attackers to bypass ACL restrictions by changing the case of file paths.  Vulnerable snippet:   ```python # https://github.com/gradio-app/gradio/blob/main/gradio/utils.py#L1500-L1517 def is_allowed_file(     path: Path,     blocked_paths: Sequence[str | Path],     allowed_paths: Sequence[str | Path],     created_paths: Sequence[str | Path], ) -> tuple[     bool, Literal[\"in_blocklist\", \"allowed\", \"created\", \"not_created_or_allowed\"] ]:     in_blocklist = any(         is_in_or_equal(path, blocked_path) for blocked_path in blocked_paths     )     if in_blocklist:         return False, \"in_blocklist\"     if any(is_in_or_equal(path, allowed_path) for allowed_path in allowed_paths):         return True, \"allowed\"     if any(is_in_or_equal(path, created_path) for created_path in created_paths):         return True, \"created\"     return False, \"not_created_or_allowed\" ```  Gradio relies on `is_in_or_equal` to determine if a file path is restricted. However, this logic fails to handle case variations in paths on case-insensitive file systems, leading to the bypass.  ## Proof of Concept (PoC)  ### Steps to Reproduce  - Deploy a Gradio demo app on a case-insensitive operating system (e.g., Windows or macOS).    ```bash   import gradio as gr   def update(name):       return f\"Welcome to Gradio, {name}!\"      with gr.Blocks() as demo:       gr.Markdown(\"Start typing below and then click **Run** to see the output.\")       with gr.Row():           inp = gr.Textbox(placeholder=\"What is your name?\")           out = gr.Textbox()       btn = gr.Button(\"Run\")       btn.click(fn=update, inputs=inp, outputs=out)      demo.launch(blocked_paths=['resources/admin'], allowed_paths=['resources/'])   ```  - Set up the file system:    - Create a folder named `resources` in the same directory as the app, containing a file `1.txt`.    - Inside the `resources` folder, create a subfolder named `admin` containing a sensitive file `credential.txt` (this file should be inaccessible due to `blocked_paths`).  - Perform the attack:    - Access the sensitive file using a case-altered path:      ```     http://127.0.0.1:PORT/gradio_api/file=resources/adMin/credential.txt     ```  ### Expected Result  Access to `resources/admin/credential.txt` should be blocked.  ### Actual Result  By altering the case in the path (e.g., `adMin`), the blocked ACL is bypassed, and unauthorized access to the sensitive file is granted.  ![image-20241119172439042](https://api.2h0ng.wiki:443/noteimages/2024/11/19/17-24-39-883969d4c31ce8a8d2a939654fab56d4.png)  This demonstration highlights that flipping the case of restricted paths allows attackers to bypass Gradio's ACL and access sensitive data.  ## Remediation Recommendations  1. **Normalize Path Case**:     - Before evaluating paths against the ACL, normalize the case of both the requested path and the blocked paths (e.g., convert all paths to lowercase).     - Example:       ```python      normalized_path = str(path).lower()      normalized_blocked_paths = [str(p).lower() for p in blocked_paths]      ```  2. **Update Documentation**:     - Warn developers about potential risks when deploying Gradio on case-insensitive file systems.  3. **Release Security Patches**:     - Notify users of the vulnerability and release an updated version of Gradio with the fixed logic.  ## ",
      "cve": "CVE-2025-23042",
      "urls": [],
      "fix_available": true,
      "fix_version": "5.11.0",
      "source": "pip-audit"
    },
    {
      "id": "GHSA-8jw3-6x8j-v96g",
      "package": "gradio",
      "version": "5.10.0",
      "severity": "unknown",
      "description": "An arbitrary file copy vulnerability in Gradio's flagging feature allows unauthenticated attackers to copy any readable file from the server's filesystem. While attackers can't read these copied files, they can cause DoS by copying large files (like /dev/urandom) to fill disk space.  ### Description The flagging component doesn't properly validate file paths before copying files. Attackers can send specially crafted requests to the `/gradio_api/run/predict` endpoint to trigger these file copies.  **Source**: User-controlled `path` parameter in the flagging functionality JSON payload   **Sink**: `shutil.copy` operation in `FileData._copy_to_dir()` method  The vulnerable code flow: 1. A JSON payload is sent to the `/gradio_api/run/predict` endpoint 2. The `path` field within `FileData` object can reference any file on the system 3. When processing this request, the `Component.flag()` method creates a `GradioDataModel` object 4. The `FileData._copy_to_dir()` method uses this path without proper validation:  ```python def _copy_to_dir(self, dir: str) -> FileData:     pathlib.Path(dir).mkdir(exist_ok=True)     new_obj = dict(self)      if not self.path:         raise ValueError(\"Source file path is not set\")     new_name = shutil.copy(self.path, dir)  # vulnerable sink     new_obj[\"path\"] = new_name     return self.__class__(**new_obj) ``` 5. The lack of validation allows copying any file the Gradio process can read  ### PoC The following script demonstrates the vulnerability by copying `/etc/passwd` from the server to Gradio's flagged directory:   Setup a Gradio app:  ```python import gradio as gr  def image_classifier(inp):     return {'cat': 0.2, 'dog': 0.8}  test = gr.Interface(fn=image_classifier, inputs=\"image\", outputs=\"label\")  test.launch(share=True) ```  Run the PoC:  ```python import requests  url = \"https://[your-gradio-app-url]/gradio_api/run/predict\"   headers = {     \"Content-Type\": \"application/json\",       \"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36\"  }  payload = {     \"data\": [         {             \"path\": \"/etc/passwd\",               \"url\": \"[your-gradio-app-url]\",             \"orig_name\": \"network_config\",              \"size\": 5000,               \"mime_type\": \"text/plain\",              \"meta\": {                 \"_type\": \"gradio.FileData\"               }         },         {}       ],     \"event_data\": None,     \"fn_index\": 4,      \"trigger_id\": 11,      \"session_hash\": \"test123\"   }  response = requests.post(url, headers=headers, json=payload) print(f\"Status Code: {response.status_code}\") print(f\"Response Body: {response.text}\") ```",
      "cve": "CVE-2025-48889",
      "urls": [],
      "fix_available": true,
      "fix_version": "5.31.0",
      "source": "pip-audit"
    },
    {
      "id": "GHSA-x39x-9qw5-ghrf",
      "package": "browser-use",
      "version": "0.1.37",
      "severity": "unknown",
      "description": "### Summary   During a manual source code review, [**ARIMLABS.AI**](https://arimlabs.ai) researchers identified that the `browser_use` module includes an embedded whitelist functionality to restrict URLs that can be visited. This restriction is enforced during agent initialization. However, it was discovered that these measures can be bypassed, leading to severe security implications.    ### Details   **File:** `browser_use/browser/context.py`    The `BrowserContextConfig` class defines an `allowed_domains` list, which is intended to limit accessible domains. This list is checked in the `_is_url_allowed()` method before navigation:  ```python @dataclass class BrowserContextConfig:     \"\"\"     [STRIPPED]     \"\"\"     cookies_file: str | None = None     minimum_wait_page_load_time: float = 0.5     wait_for_network_idle_page_load_time: float = 1     maximum_wait_page_load_time: float = 5     wait_between_actions: float = 1      disable_security: bool = True      browser_window_size: BrowserContextWindowSize = field(default_factory=lambda: {'width': 1280, 'height': 1100})     no_viewport: Optional[bool] = None      save_recording_path: str | None = None     save_downloads_path: str | None = None     trace_path: str | None = None     locale: str | None = None     user_agent: str = (         'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/85.0.4183.102 Safari/537.36'     )      highlight_elements: bool = True     viewport_expansion: int = 500     allowed_domains: list[str] | None = None     include_dynamic_attributes: bool = True      _force_keep_context_alive: bool = False ``` The _is_url_allowed() method is responsible for checking whether a given URL is permitted: ```python def _is_url_allowed(self, url: str) -> bool:     \"\"\"Check if a URL is allowed based on the whitelist configuration.\"\"\"     if not self.config.allowed_domains:         return True      try:         from urllib.parse import urlparse          parsed_url = urlparse(url)         domain = parsed_url.netloc.lower()          # Remove port number if present         if ':' in domain:             domain = domain.split(':')[0]          # Check if domain matches any allowed domain pattern         return any(             domain == allowed_domain.lower() or domain.endswith('.' + allowed_domain.lower())             for allowed_domain in self.config.allowed_domains         )     except Exception as e:         logger.error(f'Error checking URL allowlist: {str(e)}')         return False ``` The core issue stems from the line `domain = domain.split(':')[0]`, which allows an attacker to manipulate basic authentication credentials by providing a username:password pair. By replacing the username with a whitelisted domain, the check can be bypassed, even though the actual domain remains different. ### Proof of Concept (PoC)  Set allowed_domains to ['example.com'] and use the following URL:  https://example.com:pass@localhost:8080  This allows bypassing all whitelist controls and accessing restricted internal services. ### Impact  - Affected all users relying on this functionality for security. - Potential for unauthorized enumeration of localhost services and internal networks. - Ability to bypass domain whitelisting, leading to unauthorized browsing.",
      "cve": "CVE-2025-47241",
      "urls": [],
      "fix_available": true,
      "fix_version": "0.1.45",
      "source": "pip-audit"
    },
    {
      "id": "GHSA-9548-qrrj-x5pj",
      "package": "aiohttp",
      "version": "3.11.14",
      "severity": "unknown",
      "description": "### Summary The Python parser is vulnerable to a request smuggling vulnerability due to not parsing trailer sections of an HTTP request.  ### Impact If a pure Python version of aiohttp is installed (i.e. without the usual C extensions) or AIOHTTP_NO_EXTENSIONS is enabled, then an attacker may be able to execute a request smuggling attack to bypass certain firewalls or proxy protections.  ----  Patch: https://github.com/aio-libs/aiohttp/commit/e8d774f635dc6d1cd3174d0e38891da5de0e2b6a",
      "cve": "CVE-2025-53643",
      "urls": [],
      "fix_available": true,
      "fix_version": "3.12.14",
      "source": "pip-audit"
    },
    {
      "id": "GHSA-9hjg-9r4m-mvj7",
      "package": "requests",
      "version": "2.32.3",
      "severity": "unknown",
      "description": "### Impact  Due to a URL parsing issue, Requests releases prior to 2.32.4 may leak .netrc credentials to third parties for specific maliciously-crafted URLs.  ### Workarounds For older versions of Requests, use of the .netrc file can be disabled with `trust_env=False` on your Requests Session ([docs](https://requests.readthedocs.io/en/latest/api/#requests.Session.trust_env)).  ### References https://github.com/psf/requests/pull/6965 https://seclists.org/fulldisclosure/2025/Jun/2",
      "cve": "CVE-2024-47081",
      "urls": [],
      "fix_available": true,
      "fix_version": "2.32.4",
      "source": "pip-audit"
    },
    {
      "id": "GHSA-48p4-8xcf-vxj5",
      "package": "urllib3",
      "version": "2.3.0",
      "severity": "unknown",
      "description": "urllib3 [supports](https://urllib3.readthedocs.io/en/2.4.0/reference/contrib/emscripten.html) being used in a Pyodide runtime utilizing the [JavaScript Fetch API](https://developer.mozilla.org/en-US/docs/Web/API/Fetch_API) or falling back on [XMLHttpRequest](https://developer.mozilla.org/en-US/docs/Web/API/XMLHttpRequest). This means you can use Python libraries to make HTTP requests from your browser or Node.js. Additionally, urllib3 provides [a mechanism](https://urllib3.readthedocs.io/en/2.4.0/user-guide.html#retrying-requests) to control redirects.  However, the `retries` and `redirect` parameters are ignored with Pyodide; the runtime itself determines redirect behavior.   ## Affected usages  Any code which relies on urllib3 to control the number of redirects for an HTTP request in a Pyodide runtime.   ## Impact  Redirects are often used to exploit SSRF vulnerabilities. An application attempting to mitigate SSRF or open redirect vulnerabilities by disabling redirects may remain vulnerable if a Pyodide runtime redirect mechanism is unsuitable.   ## Remediation  If you use urllib3 in Node.js, upgrade to a patched version of urllib3.  Unfortunately, browsers provide no suitable way which urllib3 can use: `XMLHttpRequest` provides no control over redirects, the Fetch API returns `opaqueredirect` responses lacking data when redirects are controlled manually. Expect default browser behavior for redirects.",
      "cve": "CVE-2025-50182",
      "urls": [],
      "fix_available": true,
      "fix_version": "2.5.0",
      "source": "pip-audit"
    },
    {
      "id": "GHSA-pq67-6m6q-mj2v",
      "package": "urllib3",
      "version": "2.3.0",
      "severity": "unknown",
      "description": "urllib3 handles redirects and retries using the same mechanism, which is controlled by the `Retry` object. The most common way to disable redirects is at the request level, as follows:  ```python resp = urllib3.request(\"GET\", \"https://httpbin.org/redirect/1\", redirect=False) print(resp.status) # 302 ```  However, it is also possible to disable redirects, for all requests, by instantiating a `PoolManager` and specifying `retries` in a way that disable redirects:  ```python import urllib3  http = urllib3.PoolManager(retries=0)  # should raise MaxRetryError on redirect http = urllib3.PoolManager(retries=urllib3.Retry(redirect=0))  # equivalent to the above http = urllib3.PoolManager(retries=False)  # should return the first response  resp = http.request(\"GET\", \"https://httpbin.org/redirect/1\") ```  However, the `retries` parameter is currently ignored, which means all the above examples don't disable redirects.  ## Affected usages  Passing `retries` on `PoolManager` instantiation to disable redirects or restrict their number.  By default, requests and botocore users are not affected.  ## Impact  Redirects are often used to exploit SSRF vulnerabilities. An application attempting to mitigate SSRF or open redirect vulnerabilities by disabling redirects at the PoolManager level will remain vulnerable.  ## Remediation  You can remediate this vulnerability with the following steps:   * Upgrade to a patched version of urllib3. If your organization would benefit from the continued support of urllib3 1.x, please contact [sethmichaellarson@gmail.com](mailto:sethmichaellarson@gmail.com) to discuss sponsorship or contribution opportunities.  * Disable redirects at the `request()` level instead of the `PoolManager()` level.",
      "cve": "CVE-2025-50181",
      "urls": [],
      "fix_available": true,
      "fix_version": "2.5.0",
      "source": "pip-audit"
    },
    {
      "id": "GHSA-vqfr-h8mv-ghfj",
      "package": "h11",
      "version": "0.14.0",
      "severity": "unknown",
      "description": "### Impact  A leniency in h11's parsing of line terminators in chunked-coding message bodies can lead to request smuggling vulnerabilities under certain conditions.  ### Details  HTTP/1.1 Chunked-Encoding bodies are formatted as a sequence of \"chunks\", each of which consists of:  - chunk length - `\\r\\n` - `length` bytes of content - `\\r\\n`  In versions of h11 up to 0.14.0, h11 instead parsed them as:  - chunk length - `\\r\\n` - `length` bytes of content - any two bytes  i.e. it did not validate that the trailing `\\r\\n` bytes were correct, and if you put 2 bytes of garbage there it would be accepted, instead of correctly rejecting the body as malformed.  By itself this is harmless. However, suppose you have a proxy or reverse-proxy that tries to analyze HTTP requests, and your proxy has a _different_ bug in parsing Chunked-Encoding, acting as if the format is:  - chunk length - `\\r\\n` - `length` bytes of content - more bytes of content, as many as it takes until you find a `\\r\\n`  For example, [pound](https://github.com/graygnuorg/pound/pull/43) had this bug -- it can happen if an implementer uses a generic \"read until end of line\" helper to consumes the trailing `\\r\\n`.  In this case, h11 and your proxy may both accept the same stream of bytes, but interpret them differently. For example, consider the following HTTP request(s) (assume all line breaks are `\\r\\n`):  ``` GET /one HTTP/1.1 Host: localhost Transfer-Encoding: chunked  5 AAAAAXX2 45 0  GET /two HTTP/1.1 Host: localhost Transfer-Encoding: chunked  0 ```  Here h11 will interpret it as two requests, one with body `AAAAA45` and one with an empty body, while our hypothetical buggy proxy will interpret it as a single request, with body `AAAAXX20\\r\\n\\r\\nGET /two ...`. And any time two HTTP processors both accept the same string of bytes but interpret them differently, you have the conditions for a \"request smuggling\" attack. For example, if `/two` is a dangerous endpoint and the job of the reverse proxy is to stop requests from getting there, then an attacker could use a bytestream like the above to circumvent this protection.  Even worse, if our buggy reverse proxy receives two requests from different users:  ``` GET /one HTTP/1.1 Host: localhost Transfer-Encoding: chunked  5 AAAAAXX999 0 ```  ``` GET /two HTTP/1.1 Host: localhost Cookie: SESSION_KEY=abcdef... ```  ...it will consider the first request to be complete and valid, and send both on to the h11-based web server over the same socket. The server will then see the two concatenated requests, and interpret them as _one_ request to `/one` whose body includes `/two`'s session key, potentially allowing one user to steal another's credentials.  ### Patches  Fixed in h11 0.15.0.  ### Workarounds  Since exploitation requires the combination of buggy h11 with a buggy (reverse) proxy, fixing either component is sufficient to mitigate this issue.  ### Credits  Reported by Jeppe Bonde Weikop on 2025-01-09.",
      "cve": "CVE-2025-43859",
      "urls": [],
      "fix_available": true,
      "fix_version": "0.16.0",
      "source": "pip-audit"
    }
  ],
  "summary": {
    "by_severity": {
      "critical": 0,
      "high": 0,
      "medium": 0,
      "low": 0,
      "info": 0,
      "unknown": 9
    },
    "suppressed": 2,
    "total": 11
  }
}