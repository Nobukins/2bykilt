# LLM Dependency Detailed Analysis - Issue #43

**ä½œæˆæ—¥**: 2025-10-16  
**ç›®çš„**: ENABLE_LLM=false æ™‚ã« requirements-minimal.txt ã®ã¿ã§å‹•ä½œã•ã›ã‚‹ãŸã‚ã®å®Œå…¨ãªLLMä¾å­˜æ’é™¤

## ğŸ¯ é”æˆç›®æ¨™

### å¿…é ˆæ¡ä»¶
1. âœ… ENABLE_LLM=false ã§ LLMé–¢é€£ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãŒä¸€åˆ‡ä¸è¦
2. âœ… requirements-minimal.txt ã®ã¿ã§èµ·å‹•ãƒ»å‹•ä½œ
3. âœ… é…å»¶ã‚¤ãƒ³ãƒãƒ¼ãƒˆ (lazy import) ã«ã‚ˆã‚‹æ¡ä»¶ä»˜ãèª­ã¿è¾¼ã¿
4. âœ… é™çš„è§£æã§æ¤œè¨¼å¯èƒ½ãªå®Œå…¨åˆ†é›¢

## ğŸ“¦ LLMé–¢é€£ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ (æ’é™¤å¯¾è±¡)

### Tier 1: ã‚³ã‚¢LLMãƒ©ã‚¤ãƒ–ãƒ©ãƒª
- `langchain` / `langchain-*` (å…¨ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³)
- `openai`
- `anthropic`
- `deepseek`
- `ollama`

### Tier 2: æ‹¡å¼µæ©Ÿèƒ½
- `browser-use` (LLMã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆæ©Ÿèƒ½)
- `mem0ai` (ãƒ¡ãƒ¢ãƒªç®¡ç†)
- `faiss-cpu` (ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢)

## ğŸ“‹ ãƒ•ã‚¡ã‚¤ãƒ«åˆ¥LLMä¾å­˜çŠ¶æ³

### ğŸ”´ Critical - å®Œå…¨é…å»¶ãƒ­ãƒ¼ãƒ‰å¿…é ˆ

#### 1. `src/utils/llm.py` (136 lines)
**ç¾çŠ¶**: ç„¡æ¡ä»¶ã§å…¨LLMãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
```python
from openai import OpenAI
from langchain_openai import ChatOpenAI
from langchain_core.globals import get_llm_cache
from langchain_ollama import ChatOllama
# ... å¤šæ•°ã®langchain imports
```

**å¯¾å¿œ**: ãƒ•ã‚¡ã‚¤ãƒ«å…¨ä½“ã‚’æ¡ä»¶ä»˜ãã‚¤ãƒ³ãƒãƒ¼ãƒˆåŒ–
- Option A: ãƒ•ã‚¡ã‚¤ãƒ«å†’é ­ã§ `if not ENABLE_LLM: raise ImportError("LLM disabled")`
- Option B: å…¨é–¢æ•°ã‚’é…å»¶ã‚¤ãƒ³ãƒãƒ¼ãƒˆåŒ–
- **æ¨å¥¨**: Option A (ã‚·ãƒ³ãƒ—ãƒ«)

**å½±éŸ¿ç¯„å›²**: 
- `src/agent/custom_agent.py`
- `src/agent/agent_manager.py`
- ãã®ä»– LLM æ©Ÿèƒ½ã‚’ä½¿ç”¨ã™ã‚‹å…¨ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«

---

#### 2. `src/utils/deep_research.py` (426 lines)
**ç¾çŠ¶**: ä¸€éƒ¨æ¡ä»¶ä»˜ãã‚¤ãƒ³ãƒãƒ¼ãƒˆå®Ÿè£…æ¸ˆã¿ï¼ˆè¡Œ19-37ï¼‰
```python
if ENABLE_LLM:
    try:
        from src.agent.custom_agent import CustomAgent
        # ... LLMé–¢é€£ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
        LLM_RESEARCH_AVAILABLE = True
    except ImportError:
        LLM_RESEARCH_AVAILABLE = False
else:
    LLM_RESEARCH_AVAILABLE = False
```

**å•é¡Œ**: `browser-use` ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆãŒç„¡æ¡ä»¶ï¼ˆè¡Œ41-44ï¼‰
```python
from browser_use.browser.browser import BrowserConfig, Browser
from browser_use.agent.views import ActionResult
from browser_use.browser.context import BrowserContext
from browser_use.controller.service import Controller, DoneAction
```

**å¯¾å¿œ**: `browser-use` ã‚‚æ¡ä»¶ä»˜ãåŒ–
```python
if ENABLE_LLM and LLM_RESEARCH_AVAILABLE:
    from browser_use.browser.browser import BrowserConfig, Browser
    # ...
```

---

#### 3. `src/agent/` ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª (å…¨ãƒ•ã‚¡ã‚¤ãƒ«)
**ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§**:
- `custom_agent.py`
- `custom_message_manager.py`
- `custom_prompts.py`
- `custom_views.py`
- `agent_manager.py`

**ç¾çŠ¶**: LLMæ©Ÿèƒ½ã®ä¸­æ ¸ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã€langchain ã«å…¨é¢ä¾å­˜

**å¯¾å¿œ**: 
- ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãƒ¬ãƒ™ãƒ«ã§æ¡ä»¶ä»˜ãã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¬ãƒ¼ãƒ‰
- å„ãƒ•ã‚¡ã‚¤ãƒ«å†’é ­ã«è¿½åŠ :
```python
import os
from src.config.feature_flags import is_llm_enabled

if not is_llm_enabled():
    raise ImportError(
        "LLM functionality is disabled. "
        "Set ENABLE_LLM=true to use agent features."
    )
```

---

#### 4. `src/llm/docker_sandbox.py`
**ç¾çŠ¶**: LLMç”¨ã‚µãƒ³ãƒ‰ãƒœãƒƒã‚¯ã‚¹æ©Ÿèƒ½

**å¯¾å¿œ**: åŒæ§˜ã«æ¡ä»¶ä»˜ãã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¬ãƒ¼ãƒ‰

---

#### 5. `src/controller/custom_controller.py`
**ç¾çŠ¶**: `browser-use` ã«ä¾å­˜
```python
from browser_use.agent.views import ActionResult
from browser_use.browser.context import BrowserContext
from browser_use.controller.service import Controller, DoneAction
```

**å¯¾å¿œ**: æ¡ä»¶ä»˜ãã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¬ãƒ¼ãƒ‰

---

#### 6. `src/browser/custom_browser.py`, `custom_context.py`
**ç¾çŠ¶**: `browser-use` ã® Browser, BrowserContext ã‚’ãƒ©ãƒƒãƒ—

**å¯¾å¿œ**: æ¡ä»¶ä»˜ãã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¬ãƒ¼ãƒ‰

---

### ğŸŸ¡ Medium - æ¡ä»¶åˆ†å²è¿½åŠ 

#### 7. `src/ui/components/run_panel.py`
**ç¾çŠ¶**: UIè¦ç´ ã« LLM é–¢é€£ã‚¿ãƒ–ãŒå«ã¾ã‚Œã‚‹å¯èƒ½æ€§

**å¯¾å¿œ**: 
- LLMæ©Ÿèƒ½ã® UI è¦ç´ ã‚’æ¡ä»¶è¡¨ç¤º
- Gradio ã‚¿ãƒ–ã®å‹•çš„ç”Ÿæˆ

```python
def create_run_panel():
    components = [...]
    
    if is_llm_enabled():
        # LLMé–¢é€£ã‚¿ãƒ–ã‚’è¿½åŠ 
        components.append(create_llm_tab())
    
    return gr.TabbedInterface(components)
```

---

#### 8. `src/config/config_adapter.py`
**ç¾çŠ¶**: LLMè¨­å®šã®èª­ã¿è¾¼ã¿

**å¯¾å¿œ**: LLMè¨­å®šã®æ¡ä»¶èª­ã¿è¾¼ã¿
```python
def load_config():
    config = load_base_config()
    
    if is_llm_enabled():
        config.update(load_llm_config())
    
    return config
```

---

#### 9. `src/security/secret_masker.py`, `secrets_vault.py`
**ç¾çŠ¶**: LLM API ã‚­ãƒ¼ã®ãƒã‚¹ã‚­ãƒ³ã‚°å‡¦ç†ã‚’å«ã‚€å¯èƒ½æ€§

**å¯¾å¿œ**: LLMé–¢é€£ç§˜å¯†æƒ…å ±ã®æ¡ä»¶å‡¦ç†

---

#### 10. `src/utils/utils.py`
**ç¾çŠ¶**: ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•°é›†

**å¯¾å¿œ**: LLMæ©Ÿèƒ½ãƒã‚§ãƒƒã‚¯é–¢æ•°ã®è¿½åŠ 
```python
def is_llm_available() -> bool:
    """Check if LLM functionality is available."""
    try:
        from src.config.feature_flags import is_llm_enabled
        return is_llm_enabled()
    except ImportError:
        return False

def require_llm():
    """Decorator to guard LLM-requiring functions."""
    def decorator(func):
        def wrapper(*args, **kwargs):
            if not is_llm_available():
                raise RuntimeError(
                    f"{func.__name__} requires LLM functionality. "
                    "Set ENABLE_LLM=true and install full requirements."
                )
            return func(*args, **kwargs)
        return wrapper
    return decorator
```

---

### ğŸŸ¢ Low - å‚ç…§ã®ã¿ã€ä¿®æ­£ä¸è¦

#### 11. `src/ui/browser_agent.py`, `stream_manager.py`
**ç¾çŠ¶**: LLMæ©Ÿèƒ½ã‚’å‘¼ã³å‡ºã™å´

**å¯¾å¿œ**: ã™ã§ã«æ¡ä»¶åˆ†å²ã•ã‚Œã¦ã„ã‚‹å¯èƒ½æ€§ã€‚è¦ç¢ºèªã€‚

---

## ğŸ› ï¸ å®Ÿè£…æˆ¦ç•¥

### Phase 1: ã‚³ã‚¢ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®é…å»¶ãƒ­ãƒ¼ãƒ‰åŒ–

#### Step 1.1: `src/utils/llm.py` ã®å®Œå…¨åˆ†é›¢
```python
# src/utils/llm.py - æ–°ã—ã„å†’é ­
"""
LLM utility functions.
Requires ENABLE_LLM=true and full requirements.txt installation.
"""
import os
from src.config.feature_flags import is_llm_enabled

if not is_llm_enabled():
    raise ImportError(
        "LLM functionality is disabled. "
        "Set ENABLE_LLM=true and install requirements.txt (not requirements-minimal.txt) "
        "to use LLM features."
    )

# æ—¢å­˜ã® import æ–‡ã¯ãã®ã¾ã¾
from openai import OpenAI
from langchain_openai import ChatOpenAI
# ...
```

#### Step 1.2: `src/agent/*` ã®å®Œå…¨åˆ†é›¢
å„ãƒ•ã‚¡ã‚¤ãƒ«ã«åŒæ§˜ã®ã‚¬ãƒ¼ãƒ‰ã‚’è¿½åŠ 

#### Step 1.3: `src/utils/deep_research.py` ã®ä¿®æ­£
`browser-use` ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚’æ¡ä»¶åŒ–:
```python
if ENABLE_LLM and LLM_RESEARCH_AVAILABLE:
    from browser_use.browser.browser import BrowserConfig, Browser
    from browser_use.agent.views import ActionResult
    from browser_use.browser.context import BrowserContext
    from browser_use.controller.service import Controller, DoneAction
else:
    # Stub classes
    class BrowserConfig: pass
    class Browser: pass
    class ActionResult: pass
    class BrowserContext: pass
    class Controller: pass
    class DoneAction: pass
```

---

### Phase 2: UI/è¨­å®šã®æ¡ä»¶åˆ†å²

#### Step 2.1: UI ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®å‹•çš„æ§‹ç¯‰
`src/ui/components/run_panel.py`:
```python
def create_tabs():
    tabs = []
    tabs.append(create_base_tabs())  # åŸºæœ¬ã‚¿ãƒ–
    
    if is_llm_enabled():
        tabs.append(create_llm_tabs())  # LLMã‚¿ãƒ–
    
    return tabs
```

#### Step 2.2: è¨­å®šã®æ¡ä»¶èª­ã¿è¾¼ã¿
`src/config/config_adapter.py`:
```python
def load_full_config():
    config = load_minimal_config()
    
    if is_llm_enabled():
        try:
            config.update(load_llm_config())
        except ImportError as e:
            logger.warning(f"LLM config skipped: {e}")
    
    return config
```

---

### Phase 3: é™çš„è§£æã¨ãƒ†ã‚¹ãƒˆ

#### Step 3.1: æ¤œè¨¼ã‚¹ã‚¯ãƒªãƒ—ãƒˆä½œæˆ
```python
# scripts/verify_llm_isolation.py
import subprocess
import sys

def test_minimal_imports():
    """Test that minimal env can start without LLM packages."""
    code = """
import sys
import os
os.environ['ENABLE_LLM'] = 'false'

# Try importing main modules
from src.config import config_adapter
from src.utils import utils
from src.browser import browser_config
# Skip: from src.agent import custom_agent  # Should not import

print("âœ… Minimal imports successful")
"""
    
    result = subprocess.run(
        [sys.executable, "-c", code],
        capture_output=True,
        text=True
    )
    
    if result.returncode != 0:
        print(f"âŒ Minimal import test failed:\n{result.stderr}")
        return False
    
    print(result.stdout)
    return True

def verify_no_llm_packages():
    """Verify LLM packages are not imported in minimal mode."""
    forbidden = [
        'langchain', 'openai', 'anthropic', 
        'browser-use', 'mem0', 'ollama'
    ]
    
    code = """
import sys
import os
os.environ['ENABLE_LLM'] = 'false'

# Import main app
from src import bykilt

# Check loaded modules
llm_modules = [m for m in sys.modules if any(pkg in m for pkg in {forbidden})]
if llm_modules:
    print(f"âŒ LLM modules found: {llm_modules}")
    sys.exit(1)
else:
    print("âœ… No LLM modules loaded")
""".format(forbidden=forbidden)
    
    result = subprocess.run(
        [sys.executable, "-c", code],
        capture_output=True,
        text=True
    )
    
    return result.returncode == 0

if __name__ == "__main__":
    tests = [
        ("Minimal imports", test_minimal_imports),
        ("No LLM packages", verify_no_llm_packages),
    ]
    
    failed = []
    for name, test_func in tests:
        print(f"\nğŸ” Running: {name}")
        if not test_func():
            failed.append(name)
    
    if failed:
        print(f"\nâŒ Failed tests: {', '.join(failed)}")
        sys.exit(1)
    else:
        print("\nâœ… All verification tests passed!")
        sys.exit(0)
```

#### Step 3.2: ãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆæ‹¡å¼µ
```python
# tests/integration/test_minimal_env.py
import pytest
import os
import subprocess
import sys

@pytest.fixture
def minimal_env():
    """Setup minimal environment."""
    env = os.environ.copy()
    env['ENABLE_LLM'] = 'false'
    return env

def test_app_starts_without_llm(minimal_env):
    """Test that app can start with ENABLE_LLM=false."""
    code = """
import os
os.environ['ENABLE_LLM'] = 'false'
from src.config.feature_flags import is_llm_enabled
assert not is_llm_enabled()
print("âœ… App started in minimal mode")
"""
    result = subprocess.run(
        [sys.executable, "-c", code],
        env=minimal_env,
        capture_output=True,
        text=True
    )
    assert result.returncode == 0
    assert "âœ…" in result.stdout

def test_llm_imports_raise_error(minimal_env):
    """Test that LLM imports raise appropriate errors."""
    code = """
import os
os.environ['ENABLE_LLM'] = 'false'
try:
    from src.utils import llm
    print("âŒ Should have raised ImportError")
    exit(1)
except ImportError as e:
    assert "LLM functionality is disabled" in str(e)
    print("âœ… Correct ImportError raised")
"""
    result = subprocess.run(
        [sys.executable, "-c", code],
        env=minimal_env,
        capture_output=True,
        text=True
    )
    assert result.returncode == 0
    assert "âœ…" in result.stdout

def test_no_forbidden_packages_loaded(minimal_env):
    """Ensure no LLM packages are loaded in minimal mode."""
    code = """
import sys
import os
os.environ['ENABLE_LLM'] = 'false'

# Import main application
# (Add actual import path)

forbidden = ['langchain', 'openai', 'anthropic', 'browser_use', 'mem0', 'ollama']
loaded_forbidden = [m for m in sys.modules if any(pkg in m for pkg in forbidden)]

if loaded_forbidden:
    print(f"âŒ Forbidden packages loaded: {loaded_forbidden}")
    exit(1)
else:
    print("âœ… No forbidden packages loaded")
"""
    result = subprocess.run(
        [sys.executable, "-c", code],
        env=minimal_env,
        capture_output=True,
        text=True
    )
    assert result.returncode == 0
```

---

## ğŸ“Š å½±éŸ¿ç¯„å›²ãƒãƒˆãƒªã‚¯ã‚¹

| ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ« | LLMä¾å­˜ | å¯¾å¿œå„ªå…ˆåº¦ | å¯¾å¿œæ–¹æ³• | å·¥æ•° |
|-----------|---------|-----------|---------|------|
| `src/utils/llm.py` | å®Œå…¨ | P0 | ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¬ãƒ¼ãƒ‰ | 0.5h |
| `src/agent/*` (5files) | å®Œå…¨ | P0 | ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¬ãƒ¼ãƒ‰ | 1h |
| `src/llm/*` | å®Œå…¨ | P0 | ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¬ãƒ¼ãƒ‰ | 0.5h |
| `src/utils/deep_research.py` | éƒ¨åˆ† | P0 | browser-useæ¡ä»¶åŒ– | 1h |
| `src/controller/custom_controller.py` | å®Œå…¨ | P0 | ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¬ãƒ¼ãƒ‰ | 0.5h |
| `src/browser/custom_*.py` | å®Œå…¨ | P0 | ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¬ãƒ¼ãƒ‰ | 0.5h |
| `src/ui/components/run_panel.py` | å‚ç…§ | P1 | æ¡ä»¶åˆ†å² | 1h |
| `src/config/config_adapter.py` | å‚ç…§ | P1 | æ¡ä»¶åˆ†å² | 0.5h |
| `src/security/*` | å‚ç…§ | P2 | æ¡ä»¶åˆ†å² | 0.5h |
| `src/utils/utils.py` | ãªã— | P1 | ãƒ˜ãƒ«ãƒ‘ãƒ¼è¿½åŠ  | 0.5h |
| `scripts/verify_llm_isolation.py` | - | P0 | æ–°è¦ä½œæˆ | 2h |
| `tests/integration/test_minimal_env.py` | - | P0 | æ–°è¦ä½œæˆ | 2h |
| ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ›´æ–° | - | P1 | æ›´æ–° | 1h |

**ç·å·¥æ•°è¦‹ç©ã‚‚ã‚Š**: ç´„ 12-15æ™‚é–“ (1.5-2æ—¥)

---

## âœ… æ¤œè¨¼ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ

### Phase 1å®Œäº†æ™‚
- [ ] `src/utils/llm.py` ãŒENABLE_LLM=falseæ™‚ã«ImportError
- [ ] `src/agent/*` å…¨ãƒ•ã‚¡ã‚¤ãƒ«ãŒæ¡ä»¶ä»˜ãã‚¤ãƒ³ãƒãƒ¼ãƒˆåŒ–
- [ ] `src/utils/deep_research.py` ã®browser-useæ¡ä»¶åŒ–
- [ ] å…¨LLMé–¢é€£ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã«ã‚¬ãƒ¼ãƒ‰å®Ÿè£…

### Phase 2å®Œäº†æ™‚
- [ ] UI ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®æ¡ä»¶è¡¨ç¤ºå®Ÿè£…
- [ ] è¨­å®šãƒ­ãƒ¼ãƒ€ãƒ¼ã®æ¡ä»¶åˆ†å²å®Ÿè£…
- [ ] ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®æ¡ä»¶å‡¦ç†å®Ÿè£…

### Phase 3å®Œäº†æ™‚
- [ ] `scripts/verify_llm_isolation.py` ä½œæˆãƒ»å®Ÿè¡ŒæˆåŠŸ
- [ ] `tests/integration/test_minimal_env.py` å…¨ãƒ†ã‚¹ãƒˆé€šé
- [ ] requirements-minimal.txt ã®ã¿ã§ã‚¢ãƒ—ãƒªèµ·å‹•æˆåŠŸ
- [ ] `sys.modules` ã« langchain/openai/anthropic ç­‰ãŒå«ã¾ã‚Œãªã„ã“ã¨ã‚’ç¢ºèª

### æœ€çµ‚ç¢ºèª
- [ ] é™çš„è§£æã‚¹ã‚¯ãƒªãƒ—ãƒˆãŒCIçµ±åˆæ¸ˆã¿
- [ ] ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ›´æ–°å®Œäº†
- [ ] PRä½œæˆãƒ»ãƒ¬ãƒ“ãƒ¥ãƒ¼ä¾é ¼
- [ ] Issue #43 ã‚¯ãƒ­ãƒ¼ã‚º

---

## ğŸ“ å­¦ç¿’ãƒªã‚½ãƒ¼ã‚¹

### Python é…å»¶ã‚¤ãƒ³ãƒãƒ¼ãƒˆã®ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹
- ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãƒ¬ãƒ™ãƒ«ã‚¬ãƒ¼ãƒ‰: æœ€ã‚‚ã‚·ãƒ³ãƒ—ãƒ«ã€æ¨å¥¨
- é–¢æ•°å†…ã‚¤ãƒ³ãƒãƒ¼ãƒˆ: ç´°ã‹ã„åˆ¶å¾¡ãŒå¯èƒ½ã ãŒè¤‡é›‘
- `TYPE_CHECKING`: å‹ãƒ’ãƒ³ãƒˆã®ã¿ã®å ´åˆã«æœ‰åŠ¹

### å‚è€ƒã‚³ãƒ¼ãƒ‰
```python
# ãƒ‘ã‚¿ãƒ¼ãƒ³1: ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãƒ¬ãƒ™ãƒ«ã‚¬ãƒ¼ãƒ‰ (æ¨å¥¨)
if not ENABLE_FEATURE:
    raise ImportError("Feature disabled")

# ãƒ‘ã‚¿ãƒ¼ãƒ³2: é–¢æ•°å†…é…å»¶ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
def feature_function():
    if ENABLE_FEATURE:
        from expensive_module import ExpensiveClass
        return ExpensiveClass()
    else:
        raise RuntimeError("Feature disabled")

# ãƒ‘ã‚¿ãƒ¼ãƒ³3: TYPE_CHECKING (å‹ãƒ’ãƒ³ãƒˆã®ã¿)
from typing import TYPE_CHECKING
if TYPE_CHECKING:
    from expensive_module import ExpensiveClass
```

---

## ğŸ“š æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—

1. âœ… **ã“ã®åˆ†æãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ãƒ¬ãƒ“ãƒ¥ãƒ¼**
2. â†’ **Phase 1.1 é–‹å§‹**: `src/utils/llm.py` ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¬ãƒ¼ãƒ‰å®Ÿè£…
3. â†’ **Phase 1.2**: `src/agent/*` ã®æ¡ä»¶åŒ–
4. â†’ **Phase 1.3**: ãã®ä»–ã‚³ã‚¢ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®æ¡ä»¶åŒ–
5. â†’ **Phase 2**: UI/è¨­å®šã®æ¡ä»¶åˆ†å²
6. â†’ **Phase 3**: æ¤œè¨¼ãƒ»ãƒ†ã‚¹ãƒˆ
7. â†’ **PRä½œæˆ**

---

**ä½œæˆè€…**: GitHub Copilot  
**ãƒ¬ãƒ“ãƒ¥ãƒ¼å¾…ã¡**: Yes  
**é–¢é€£Issue**: #43
