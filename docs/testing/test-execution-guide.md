# Test Execution Guide# Test Execution Guide



ã“ã®ã‚¬ã‚¤ãƒ‰ã¯ã€ãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆã®å®Ÿè¡Œæ–¹æ³•ã€ä¾å­˜é–¢ä¿‚ç®¡ç†ã€ãƒ†ã‚¹ãƒˆåˆ†é›¢ã€æˆæœç‰©ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã€ã‚¤ãƒ™ãƒ³ãƒˆãƒ«ãƒ¼ãƒ—ç®¡ç†ãªã©ã€ãƒ†ã‚¹ãƒˆå®Ÿè¡Œã«ãŠã‘ã‚‹åŒ…æ‹¬çš„ãªçŸ¥è­˜ã‚’æä¾›ã—ã¾ã™ã€‚This guide documents how to run, filter, and maintain the 2bykilt test suite after the async stabilization & skip reduction work (106 â†’ 31 skips).



## ç›®æ¬¡## Quick Start



1. [ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆ](#ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆ)```bash

2. [ç’°å¢ƒå¤‰æ•°ã¨ãã®å½±éŸ¿](#ç’°å¢ƒå¤‰æ•°ã¨ãã®å½±éŸ¿)# Run full suite (fastest typical path) â€“ skips env-gated tests automatically

3. [ãƒ†ã‚¹ãƒˆåˆ†é›¢ã¨å®Ÿè¡Œé †åº](#ãƒ†ã‚¹ãƒˆåˆ†é›¢ã¨å®Ÿè¡Œé †åº)pytest -q

4. [ä¾å­˜é–¢ä¿‚ç®¡ç†](#ä¾å­˜é–¢ä¿‚ç®¡ç†)

5. [æˆæœç‰©ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã¨å†ç¾æ€§](#æˆæœç‰©ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã¨å†ç¾æ€§)# Focus on batch engine (recently refactored async logic)

6. [ã‚¤ãƒ™ãƒ³ãƒˆãƒ«ãƒ¼ãƒ—ç®¡ç†](#ã‚¤ãƒ™ãƒ³ãƒˆãƒ«ãƒ¼ãƒ—ç®¡ç†)pytest tests/test_batch_engine.py -v

7. [ãƒ†ã‚¹ãƒˆãƒ¬ã‚¤ãƒ¤ãƒ¼ã¨ãƒãƒ¼ã‚«ãƒ¼](#ãƒ†ã‚¹ãƒˆãƒ¬ã‚¤ãƒ¤ãƒ¼ã¨ãƒãƒ¼ã‚«ãƒ¼)

8. [ãƒ—ãƒƒã‚·ãƒ¥å‰æ¤œè¨¼](#ãƒ—ãƒƒã‚·ãƒ¥å‰æ¤œè¨¼)# Run Feature Flag tests (Issue #272 - Admin UI & new API methods)

9. [ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°æ±ºå®šæœ¨](#ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°æ±ºå®šæœ¨)pytest tests/unit/ui/admin/ tests/unit/config/test_feature_flags_new_methods.py -v

10. [ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹](#ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹)

# Run only non-LLM unit-ish layers (safe in minimal env)

---pytest -m "not integration and not local_only" -q

```

## ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆ

## Environment Flags & Their Effects

```bash

# CIç’°å¢ƒã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆãƒ—ãƒƒã‚·ãƒ¥å‰ã®æ¨å¥¨æ¤œè¨¼ï¼‰| Variable | Values | Effect |

unset BYKILT_ENV|----------|--------|--------|

ENABLE_LLM=true pytest -m "ci_safe" --cov=src --cov-report=term -v| ENABLE_LLM | true/false | Enables LLM-dependent tests (currently 1 test skipped when false) |

| RUN_LOCAL_FINAL_VERIFICATION | 1 unset | Enables heavy local verification tests (UI/browser + recording) |

# ç‰¹å®šã®ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’å®Ÿè¡Œ| RUN_LOCAL_INTEGRATION | 1 unset | Enables broader integration tests (network/browser/profile) |

pytest tests/path/to/test_file.py -v

Unset values are treated as disabled.

# ã‚«ãƒãƒ¬ãƒƒã‚¸ãƒ¬ãƒãƒ¼ãƒˆä»˜ãã§å®Ÿè¡Œ

pytest tests/path/to/test_file.py --cov=src --cov-report=html## Remaining Skip Categories (Snapshot)



# ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒãƒ³ã‚°ã§ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ| Category | Approx Count | Reason | Re-enable Path |

pytest -k "test_pattern" -v|----------|--------------|--------|----------------|

| LLM-dependent | 1 | Requires model + tokens | Set ENABLE_LLM=true |

# å®Œå…¨ã‚¯ãƒªãƒ¼ãƒ³ç’°å¢ƒã§ã®å®Ÿè¡Œï¼ˆæœ€ã‚‚ç¢ºå®Ÿï¼‰| local_only (final verification) | ~10 | Long-running / interactive | Export RUN_LOCAL_FINAL_VERIFICATION=1 |

./scripts/clean_test_artifacts.sh| integration | ~12 | Browser/env dependent & slower | Export RUN_LOCAL_INTEGRATION=1 |

./scripts/clean_test_logs.sh| git_script_integration (mocking gap) | 8 | Resolver injection not mockable yet | Refactor get_git_script_resolver (planned) |

unset BYKILT_ENV

ENABLE_LLM=true pytest -m "ci_safe" --cov=src --cov-report=term -vExact counts may shift slightly as tests evolve.

```

## Typical Test Layers / Markers (Current State)

---

Project already uses pragmatic environment gating; a future issue (#81) proposes formal marker taxonomy (unit, integration, browser, slow, etc.). Until then:

## ç’°å¢ƒå¤‰æ•°ã¨ãã®å½±éŸ¿

- local_only: Explicitly opt-in heavy / environment sensitive tests

### ã‚³ã‚¢ç’°å¢ƒå¤‰æ•°- integration: Broader multi-component flows

- (future) browser, unit, slow: To be added per #81 acceptance criteria

| å¤‰æ•° | å€¤ | å½±éŸ¿ |

|------|-----|------|## Running Specific Layers

| `ENABLE_LLM` | true/false | LLMä¾å­˜æ©Ÿèƒ½ã¨ãƒ†ã‚¹ãƒˆã®æœ‰åŠ¹åŒ–ï¼ˆCI ã§ã¯ `true` ãŒå¿…é ˆï¼‰ |

| `BYKILT_ENV` | unset/dev/staging/prod | è¨­å®šç’°å¢ƒã®é¸æŠï¼ˆCI ã§ã¯æœªè¨­å®š = ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆç’°å¢ƒï¼‰ |```bash

| `RUN_LOCAL_INTEGRATION` | 1/unset | çµ±åˆãƒ†ã‚¹ãƒˆã®å®Ÿè¡Œåˆ¶å¾¡ |# Opt into integration tests

| `RUN_LOCAL_FINAL_VERIFICATION` | 1/unset | é‡ã„æ¤œè¨¼ãƒ†ã‚¹ãƒˆã®å®Ÿè¡Œåˆ¶å¾¡ |RUN_LOCAL_INTEGRATION=1 pytest -m integration -v



### é‡è¦ãªæ³¨æ„äº‹é …# Opt into final verification

RUN_LOCAL_FINAL_VERIFICATION=1 pytest -m local_only -v

âš ï¸ **CIç’°å¢ƒã¨ã®ä¸€è‡´**ï¼š

- CIã§ã¯ `BYKILT_ENV` ãŒæœªè¨­å®š# Include LLM tests

- ãƒ­ãƒ¼ã‚«ãƒ«ã§ `BYKILT_ENV=dev` ãŒè¨­å®šã•ã‚Œã¦ã„ã‚‹ã¨ã€CI ã¨ç•°ãªã‚‹å‹•ä½œã‚’ã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ENABLE_LLM=true pytest -m "not local_only" -v

- **ãƒ—ãƒƒã‚·ãƒ¥å‰ã«ã¯å¿…ãš `unset BYKILT_ENV` ã‚’å®Ÿè¡Œ**```



```bash### Artifact capture integration checks

# âŒ NG: ç’°å¢ƒå¤‰æ•°ãŒè¨­å®šã•ã‚ŒãŸã¾ã¾ãƒ†ã‚¹ãƒˆ

export BYKILT_ENV=devThe browser automation pipeline now has a focused regression around artifact generation. It exercises both the script-based demo runner and the direct browser-control flow, asserting that screenshots, element captures, and recordings are persisted in the run directory. Run it locally with integration tests enabled:

pytest -m "ci_safe" -v  # CI ã¨ç•°ãªã‚‹å‹•ä½œã®å¯èƒ½æ€§

```bash

# âœ… OK: CIç’°å¢ƒã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆRUN_LOCAL_INTEGRATION=1 pytest tests/integration/test_artifact_capture.py -vv

unset BYKILT_ENV```

ENABLE_LLM=true pytest -m "ci_safe" -v

```The suite writes to a temp `ARTIFACTS_BASE_DIR`, so existing local artifacts are untouched. On success you should see one `*-art` run folder per test containing `screenshots/`, `elements/`, and `videos/` entries plus the standard `manifest_v2.json`.



### ç’°å¢ƒå¤‰æ•°ã®å„ªå…ˆé †ä½### Feature Flag Admin UI tests (Issue #272)



1. **ç’°å¢ƒå¤‰æ•°** (`BYKILT_ENV`, `ENABLE_LLM`)The Feature Flag admin UI and API enhancement tests verify:

2. **è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«** (`config/base.yml`, `config/dev/`)- **UI Component**: Gradio panel creation, data loading, filtering, and search functionality

3. **ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤** (ã‚³ãƒ¼ãƒ‰å†…ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯)- **API Methods**: `get_all_flags()` and `get_flag_metadata()` with thread-safety, override handling, and consistency checks

- **Coverage**: 21 tests total (11 UI tests, 10 API tests)

---

Run these tests with:

## ãƒ†ã‚¹ãƒˆåˆ†é›¢ã¨å®Ÿè¡Œé †åº

```bash

### ãªãœãƒ†ã‚¹ãƒˆé †åºãŒé‡è¦ã‹# All Feature Flag tests

pytest tests/unit/ui/admin/ tests/unit/config/test_feature_flags_new_methods.py -v

**å•é¡Œ**: ãƒ­ãƒ¼ã‚«ãƒ«ã§å˜ä½“å®Ÿè¡Œã™ã‚‹ã¨æˆåŠŸã™ã‚‹ãŒã€å…¨ä½“å®Ÿè¡Œã§å¤±æ•—ã™ã‚‹ãƒ†ã‚¹ãƒˆãŒå­˜åœ¨ã™ã‚‹

# UI tests only

**åŸå› **:pytest tests/unit/ui/admin/test_feature_flag_panel.py -v

1. **çŠ¶æ…‹ã®æ±šæŸ“**: å‰ã®ãƒ†ã‚¹ãƒˆãŒæ®‹ã—ãŸçŠ¶æ…‹ï¼ˆãƒ•ã‚¡ã‚¤ãƒ«ã€ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°ã€ãƒ¢ãƒƒã‚¯ï¼‰ãŒå½±éŸ¿

2. **æˆæœç‰©ã®æ®‹å­˜**: `artifacts/runs/` ã«æ®‹ã£ãŸãƒ•ã‚¡ã‚¤ãƒ«ãŒå¾Œç¶šãƒ†ã‚¹ãƒˆã«å½±éŸ¿# API method tests only

3. **ãƒ¢ãƒƒã‚¯ã®æœªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—**: `patch()` ãŒé©åˆ‡ã«è§£é™¤ã•ã‚Œã¦ã„ãªã„pytest tests/unit/config/test_feature_flags_new_methods.py -v

4. **ã‚¤ãƒ™ãƒ³ãƒˆãƒ«ãƒ¼ãƒ—ã®æ®‹å­˜**: éåŒæœŸãƒ†ã‚¹ãƒˆã®ãƒ«ãƒ¼ãƒ—ãŒæ­£ã—ãé–‰ã˜ã‚‰ã‚Œã¦ã„ãªã„```



### ãƒ†ã‚¹ãƒˆåˆ†é›¢ã®ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹These tests use the actual feature_flags.yaml configuration and verify:

- Metadata structure (value, default, type, description, source, override_active)

#### 1. ãƒ•ã‚£ã‚¯ã‚¹ãƒãƒ£ã‚¹ã‚³ãƒ¼ãƒ—ã®é©åˆ‡ãªä½¿ç”¨- Runtime override behavior

- Thread-safe concurrent access

```python- Consistency between `get_all_flags()` and `get_flag_metadata()`

import pytest- UI filtering and search capabilities



# âŒ NG: ãƒ†ã‚¹ãƒˆã”ã¨ã«çŠ¶æ…‹ãŒå…±æœ‰ã•ã‚Œã‚‹## Async Test Conventions

@pytest.fixture(scope="module")

def shared_state():All new async tests should:

    return {"count": 0}

1. Be declared with `async def test_*` when awaiting async code directly.

# âœ… OK: å„ãƒ†ã‚¹ãƒˆã§ç‹¬ç«‹ã—ãŸçŠ¶æ…‹2. Avoid manual event loop creation/closing â€“ rely on pytest-asyncio auto mode.

@pytest.fixture(scope="function")3. Ensure any background tasks (e.g., spawned via `asyncio.create_task`) are awaited or canceled explicitly in the test body or fixture finalizer.

def isolated_state():4. Use temporary directories (`tmp_path`) and avoid persisting state in `artifacts/` unless the test asserts on artifact outputs.

    return {"count": 0}

```## Artifact & Log Cleanup



#### 2. ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ä½¿ç”¨Two cleanup scripts (existing + new) help ensure hermetic test runs:



```python```bash

import pytest# Remove run-specific artifact directories & pytest cache

from pathlib import Path./scripts/clean_test_artifacts.sh



# âœ… OK: pytest ãŒè‡ªå‹•ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã™ã‚‹ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª# Remove logs, coverage, htmlcov, and residual run dirs (dry run first)

def test_artifact_creation(tmp_path: Path):./scripts/clean_test_logs.sh --dry-run

    artifact_dir = tmp_path / "artifacts"./scripts/clean_test_logs.sh

    artifact_dir.mkdir()

    # ãƒ†ã‚¹ãƒˆå¾Œã€tmp_path ã¯è‡ªå‹•å‰Šé™¤ã•ã‚Œã‚‹# Clean Feature Flag artifacts (if test isolation issues occur)

    assert artifact_dir.exists()rm -rf artifacts/runs/*-flags

```

# âŒ NG: å®Ÿéš›ã® artifacts/ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’æ±šæŸ“

def test_artifact_creation_bad():Recommended before large refactors or when investigating flakiness. Note: Feature Flag lazy artifact creation may generate `*-flags` directories during tests; clean these if test isolation issues occur.

    artifact_dir = Path("artifacts/runs/test-run")

    artifact_dir.mkdir(parents=True)## Common Commands

    # ãƒ†ã‚¹ãƒˆå¾Œã‚‚æ®‹ã‚Šç¶šã‘ã‚‹ï¼

``````bash

# Verbose skip reasons (inventory)

#### 3. ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã§ã®ãƒ¢ãƒƒã‚¯pytest -rs -q



```python# Single test debug

from unittest.mock import patchpytest tests/test_batch_engine.py::TestStartBatch::test_creates_new_batch -vv



# âŒ NG: ãƒ¢ãƒƒã‚¯ãŒãƒ†ã‚¹ãƒˆå¤–ã§è§£é™¤ã•ã‚Œã‚‹# Fail fast & show locals

def test_config_without_multi_env():pytest -x --showlocals

    with patch('src.utils.default_config_settings.MULTI_ENV_AVAILABLE', False):

        config = default_config()# Only modified tests since main

    # ã“ã“ã§ãƒ¢ãƒƒã‚¯ã¯æ—¢ã«è§£é™¤ã•ã‚Œã¦ã„ã‚‹pytest $(git diff --name-only origin/main | grep '^tests/' | tr '\n' ' ')

    assert config['use_multi_env'] is False  # å¤±æ•—ã™ã‚‹å¯èƒ½æ€§```



# âœ… OK: ã™ã¹ã¦ã®æ¤œè¨¼ã‚’ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå†…ã§å®Ÿè¡Œ## Adding New Tests â€“ Checklist

def test_config_without_multi_env():

    with patch('src.utils.default_config_settings.MULTI_ENV_AVAILABLE', False):- [ ] Use deterministic data (no real network unless integration-marked)

        config = default_config()- [ ] Prefer factories/fixtures for complex objects

        assert config['use_multi_env'] is False  # æˆåŠŸ- [ ] Clean up artifacts or write to tmp_path

```- [ ] Avoid real sleeps > 0.1s (use async timeouts / monkeypatch) unless integration

- [ ] If test requires environment asset (browser/profile) â€“ gate with env flag

#### 4. ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãƒ¬ãƒ™ãƒ«å¤‰æ•°ã®ãƒ¢ãƒƒã‚¯ï¼ˆIssue #340ã§ç™ºè¦‹ï¼‰

## Metrics Related Testing

```python

# src/utils/default_config_settings.pyBatch engine metrics now include `batch_jobs_stopped`. When expanding metrics:

MULTI_ENV_AVAILABLE = is_multi_env_config_available()  # ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚¤ãƒ³ãƒãƒ¼ãƒˆæ™‚ã«è©•ä¾¡

- Provide a `_record_*` helper mirroring `_record_batch_stop_metrics` pattern

# âŒ NG: æ–‡å­—åˆ—ãƒ™ãƒ¼ã‚¹ã® patch ã¯å‹•ä½œã—ãªã„- Patch/spy metric collector in tests for assertion isolation

def test_default_config():

    with patch('src.utils.default_config_settings.MULTI_ENV_AVAILABLE', False):## Dealing With git_script_integration Skips

        config = default_config()  # MULTI_ENV_AVAILABLE ã¯æ—¢ã«è©•ä¾¡æ¸ˆã¿

Current blockers: Mocking `get_git_script_resolver` and side effects of cloning/copying. Planned approach (post-PR):

# âœ… OK: patch.object() ã‚’ä½¿ç”¨

import src.utils.default_config_settings as config_module- Introduce resolver injection via fixture or parameter

- Provide lightweight in-memory or tempdir fake repo

def test_default_config():- Remove class-level skips incrementally

    with patch.object(config_module, 'MULTI_ENV_AVAILABLE', False):

        config = default_config()  # æ­£ã—ããƒ¢ãƒƒã‚¯ã•ã‚Œã‚‹## Failure Triage Flow

```

1. Re-run with `-vv -k failing_test_name` to isolate

### å®Ÿè¡Œé †åºã®å•é¡Œã‚’æ¤œå‡ºã™ã‚‹æ–¹æ³•2. If async warning appears: ensure the test function is async & awaited

3. If artifacts mismatch: run cleanup scripts and retry

```bash4. If event loop RuntimeError: check for manual loop manipulation or lingering tasks

# 1. å˜ä½“ã§å®Ÿè¡Œï¼ˆé€šå¸¸ã¯æˆåŠŸï¼‰5. If path errors inside simulation: ensure job manifest includes required task/command structure

pytest tests/path/to/test_file.py::test_specific -v

## Roadmap Links

# 2. å…¨ä½“ã§å®Ÿè¡Œï¼ˆå¤±æ•—ã™ã‚‹å¯èƒ½æ€§ï¼‰

pytest tests/path/to/test_file.py -v- Issue #263: Event loop teardown/runtime stabilization (addressed by async refactors & ordering rules)

- Issue #101: Recording stability & generation â€“ baseline stabilized, further refinements future scope

# 3. ãƒ©ãƒ³ãƒ€ãƒ é †åºã§å®Ÿè¡Œï¼ˆé †åºä¾å­˜ã‚’æ¤œå‡ºï¼‰- Issue #81: Test layering & marker formalization â€“ next structural enhancement

pip install pytest-randomly- Issue #272: Feature Flag Admin UI â€“ Gradio-based management panel with comprehensive test coverage (21 tests)

pytest tests/path/to/test_file.py --randomly-dont-shuffle  # ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³

pytest tests/path/to/test_file.py  # ãƒ©ãƒ³ãƒ€ãƒ é †åº## Known Gaps (Post-Work)



# 4. å¤±æ•—ã™ã‚‹ãƒ†ã‚¹ãƒˆã®å‰å¾Œã‚’ç‰¹å®š| Gap | Impact | Planned Remedy |

pytest tests/path/to/test_file.py -v --lf  # å‰å›ã®å¤±æ•—ã®ã¿å†å®Ÿè¡Œ|-----|--------|----------------|

pytest tests/path/to/test_file.py -v -x    # æœ€åˆã®å¤±æ•—ã§åœæ­¢| Missing formal marker schema | Harder selective CI matrix | Implement per #81 |

```| git_script resolver not injectable | 8 tests skipped | Refactor factory + fixture |

| Single remaining LLM skip | Minor coverage gap | Enable in LLM-capable CI lane |

---

## Suggested CI Profiles (Future)

## ä¾å­˜é–¢ä¿‚ç®¡ç†

| Profile | Command | Purpose |

### ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãƒ¬ãƒ™ãƒ«ã§ã®ä¾å­˜é–¢ä¿‚|---------|---------|---------|

| fast | `pytest -m "not integration and not local_only"` | PR gating |

**å•é¡Œ**: ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚¤ãƒ³ãƒãƒ¼ãƒˆæ™‚ã«è©•ä¾¡ã•ã‚Œã‚‹å¤‰æ•°ã¯ã€ãƒ†ã‚¹ãƒˆå†…ã§ãƒ¢ãƒƒã‚¯ã™ã‚‹ã®ãŒå›°é›£| extended | `RUN_LOCAL_INTEGRATION=1 pytest -m "integration and not local_only"` | Nightly/integration |

| full | `ENABLE_LLM=true RUN_LOCAL_*=1 pytest` | Exhaustive / manual release gate |

**ä¾‹**: Issue #340 ã§ç™ºè¦‹ã•ã‚ŒãŸå•é¡Œ

## Appendix â€“ Legacy Cleanup Note

```python

# src/utils/default_config_settings.py (11è¡Œç›®)Simulation tests previously assumed lightweight automation stubs; the engine now executes real automation flow requiring valid task/command fields. Old assumptions were updated; future changes should keep simulation test semantics aligned with engine contract evolution.

MULTI_ENV_AVAILABLE = is_multi_env_config_available()

---

# ã“ã®å¤‰æ•°ã¯ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒã‚¤ãƒ³ãƒãƒ¼ãƒˆã•ã‚ŒãŸç¬é–“ã«è©•ä¾¡ã•ã‚Œã‚‹Maintainers: Update this document whenever skip policy, markers, or environment flags change.

# ã¤ã¾ã‚Šã€ãƒ†ã‚¹ãƒˆé–‹å§‹å‰ã«æ—¢ã«å€¤ãŒç¢ºå®šã—ã¦ã„ã‚‹
```

### è§£æ±ºãƒ‘ã‚¿ãƒ¼ãƒ³

#### ãƒ‘ã‚¿ãƒ¼ãƒ³1: patch.object() ã®ä½¿ç”¨

```python
import src.utils.default_config_settings as config_module
from unittest.mock import patch

def test_legacy_config():
    # âœ… ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ç›´æ¥ãƒ‘ãƒƒãƒ
    with patch.object(config_module, 'MULTI_ENV_AVAILABLE', False):
        config = default_config()
        assert config['use_multi_env'] is False
```

#### ãƒ‘ã‚¿ãƒ¼ãƒ³2: é–¢æ•°åŒ–ã—ã¦é…å»¶è©•ä¾¡

```python
# âŒ NG: ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãƒ¬ãƒ™ãƒ«ã§å³åº§ã«è©•ä¾¡
MULTI_ENV_AVAILABLE = is_multi_env_config_available()

# âœ… OK: é–¢æ•°ã«ã—ã¦å‘¼ã³å‡ºã—æ™‚ã«è©•ä¾¡
def get_multi_env_available():
    return is_multi_env_config_available()

# ä½¿ç”¨æ™‚
if get_multi_env_available():
    # ...
```

### å¾ªç’°ã‚¤ãƒ³ãƒãƒ¼ãƒˆã®å›é¿

```python
# âŒ NG: å¾ªç’°ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
# module_a.py
from module_b import some_function

# module_b.py
from module_a import some_class

# âœ… OK: é…å»¶ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
# module_a.py
def use_some_function():
    from module_b import some_function
    return some_function()
```

### LLMä¾å­˜é–¢ä¿‚ã®ç®¡ç†

```python
# âœ… OK: æ¡ä»¶ä»˜ãã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from src.config.env_config import is_llm_enabled

if is_llm_enabled():
    from langchain.llms import OpenAI
    # LLMé–¢é€£ã®å‡¦ç†
else:
    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†
    pass

# ãƒ†ã‚¹ãƒˆå´
@pytest.mark.skipif(not is_llm_enabled(), reason="LLMæ©Ÿèƒ½ãŒç„¡åŠ¹")
def test_llm_feature():
    # LLMä¾å­˜ã®ãƒ†ã‚¹ãƒˆ
    pass
```

---

## æˆæœç‰©ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã¨å†ç¾æ€§

### ãªãœã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ãŒå¿…è¦ã‹

**å•é¡Œ**: ãƒ†ã‚¹ãƒˆå®Ÿè¡Œæ™‚ã«ç”Ÿæˆã•ã‚ŒãŸæˆæœç‰©ãŒæ®‹ã‚Šç¶šã‘ã€å¾Œç¶šã®ãƒ†ã‚¹ãƒˆã«å½±éŸ¿ã™ã‚‹

**å½±éŸ¿ã‚’å—ã‘ã‚„ã™ã„ã‚±ãƒ¼ã‚¹**:
1. **ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆæ¤œè¨¼ãƒ†ã‚¹ãƒˆ**: ã€Œãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒç©ºã§ã‚ã‚‹ã€ã“ã¨ã‚’æœŸå¾…ã™ã‚‹ãƒ†ã‚¹ãƒˆ
2. **ãƒ•ã‚¡ã‚¤ãƒ«ã‚«ã‚¦ãƒ³ãƒˆãƒ†ã‚¹ãƒˆ**: ã€ŒNå€‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ãŒç”Ÿæˆã•ã‚Œã‚‹ã€ã“ã¨ã‚’æ¤œè¨¼ã™ã‚‹ãƒ†ã‚¹ãƒˆ
3. **ãƒãƒ‹ãƒ•ã‚§ã‚¹ãƒˆæ¤œè¨¼**: ã€Œç‰¹å®šã®æ§‹é€ ã®JSONãŒå­˜åœ¨ã™ã‚‹ã€ã“ã¨ã‚’ç¢ºèªã™ã‚‹ãƒ†ã‚¹ãƒˆ
4. **éŒ²ç”»ãƒ•ã‚¡ã‚¤ãƒ«ãƒ†ã‚¹ãƒˆ**: ã€Œ.webm ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã™ã‚‹ã€ã“ã¨ã‚’æ¤œè¨¼ã™ã‚‹ãƒ†ã‚¹ãƒˆ

### ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

#### 1. æˆæœç‰©ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—: `scripts/clean_test_artifacts.sh`

```bash
#!/bin/bash
# ãƒ†ã‚¹ãƒˆç”Ÿæˆç‰©ã‚’å‰Šé™¤ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ã¨ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆï¼‰

./scripts/clean_test_artifacts.sh

# å‰Šé™¤å¯¾è±¡:
# - artifacts/runs/TESTRUN*-art
# - artifacts/runs/test-art
# - src/artifacts/runs/TEST*-art
# - .pytest_cache
```

**ä½¿ç”¨ã‚¿ã‚¤ãƒŸãƒ³ã‚°**:
- âœ… ãƒ—ãƒƒã‚·ãƒ¥å‰ã®æœ€çµ‚æ¤œè¨¼å‰
- âœ… ãƒ†ã‚¹ãƒˆå¤±æ•—æ™‚ã®ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°
- âœ… CIç’°å¢ƒã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å‰

#### 2. ãƒ­ã‚°ã¨ã‚«ãƒãƒ¬ãƒƒã‚¸ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—: `scripts/clean_test_logs.sh`

```bash
#!/bin/bash
# ãƒ­ã‚°ã€ã‚«ãƒãƒ¬ãƒƒã‚¸ã€ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’å‰Šé™¤

./scripts/clean_test_logs.sh --dry-run  # ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
./scripts/clean_test_logs.sh            # å®Ÿè¡Œ

# å‰Šé™¤å¯¾è±¡:
# - logs/*
# - htmlcov/
# - .coverage
# - coverage.xml
# - .pytest_cache
# - tmp/*
```

**ä½¿ç”¨ã‚¿ã‚¤ãƒŸãƒ³ã‚°**:
- âœ… ã‚«ãƒãƒ¬ãƒƒã‚¸ãƒ¬ãƒãƒ¼ãƒˆã®å†ç”Ÿæˆå‰
- âœ… ãƒ‡ã‚£ã‚¹ã‚¯å®¹é‡ã®ç¢ºä¿
- âœ… ã‚¯ãƒªãƒ¼ãƒ³ãªçŠ¶æ…‹ã‹ã‚‰ã®é–‹ç™ºé–‹å§‹æ™‚

### ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã®ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹

#### ãƒ—ãƒƒã‚·ãƒ¥å‰ã®å®Œå…¨ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼

```bash
#!/bin/bash
# pre-push-validation.sh

set -e

echo "ğŸ§¹ Step 1: ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"
./scripts/clean_test_artifacts.sh
./scripts/clean_test_logs.sh

echo "ğŸ”§ Step 2: ç’°å¢ƒè¨­å®š"
unset BYKILT_ENV
export ENABLE_LLM=true

echo "ğŸ§ª Step 3: ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ"
pytest -m "ci_safe" --cov=src --cov-report=term -v

echo "âœ… ã™ã¹ã¦ã®ãƒã‚§ãƒƒã‚¯å®Œäº†ï¼ãƒ—ãƒƒã‚·ãƒ¥å¯èƒ½ã§ã™"
```

#### ãƒ†ã‚¹ãƒˆå†…ã§ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—

```python
import pytest
from pathlib import Path
import shutil

@pytest.fixture(autouse=True)
def cleanup_artifacts():
    """å„ãƒ†ã‚¹ãƒˆã®å‰å¾Œã§ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
    # ãƒ†ã‚¹ãƒˆå‰ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
    artifact_dir = Path("artifacts/runs/test-art")
    if artifact_dir.exists():
        shutil.rmtree(artifact_dir)
    
    yield  # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    
    # ãƒ†ã‚¹ãƒˆå¾Œã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
    if artifact_dir.exists():
        shutil.rmtree(artifact_dir)
```

### Feature Flag ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—

```bash
# Feature Flag é…å»¶ç”Ÿæˆã«ã‚ˆã‚Š *-flags ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒä½œæˆã•ã‚Œã‚‹
rm -rf artifacts/runs/*-flags

# ç‰¹å®šã®ãƒ†ã‚¹ãƒˆå®Ÿè¡Œãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ã¿å‰Šé™¤
rm -rf artifacts/runs/TESTRUN-*
```

---

## ã‚¤ãƒ™ãƒ³ãƒˆãƒ«ãƒ¼ãƒ—ç®¡ç†

### ã‚¤ãƒ™ãƒ³ãƒˆãƒ«ãƒ¼ãƒ—å•é¡Œã®èƒŒæ™¯ï¼ˆIssue #263ï¼‰

**å•é¡Œ**: éåŒæœŸãƒ†ã‚¹ãƒˆã§ä»¥ä¸‹ã®ã‚¨ãƒ©ãƒ¼ãŒé »ç™º

```
RuntimeError: This event loop is already running
RuntimeError: Cannot close a running event loop
RuntimeError: Runner is closed
PytestUnhandledCoroutineWarning
```

**æ ¹æœ¬åŸå› **:
1. **æ‰‹å‹•ãƒ«ãƒ¼ãƒ—ç®¡ç†**: ãƒ†ã‚¹ãƒˆå†…ã§ `asyncio.get_event_loop()` ã‚’æ‰‹å‹•ã§ä½œæˆãƒ»é–‰ã˜ã¦ã„ã‚‹
2. **pytest-asyncio ã®ç«¶åˆ**: `pytest-asyncio` ã®è‡ªå‹•ç®¡ç†ã¨ãƒãƒƒãƒ†ã‚£ãƒ³ã‚°
3. **ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã‚¿ã‚¹ã‚¯ã®æœªå®Œäº†**: ã‚¿ã‚¹ã‚¯ãŒå®Ÿè¡Œä¸­ã®ã¾ã¾ãƒ«ãƒ¼ãƒ—ã‚’é–‰ã˜ã‚ˆã†ã¨ã™ã‚‹
4. **ãƒ•ã‚£ã‚¯ã‚¹ãƒãƒ£ã®ã‚¹ã‚³ãƒ¼ãƒ—ãƒŸã‚¹**: ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚¹ã‚³ãƒ¼ãƒ—ã®ãƒ«ãƒ¼ãƒ—ã‚’è¤‡æ•°ãƒ†ã‚¹ãƒˆã§å…±æœ‰

### ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹: pytest-asyncio ã«ä»»ã›ã‚‹

#### âŒ NG: æ‰‹å‹•ã§ã‚¤ãƒ™ãƒ³ãƒˆãƒ«ãƒ¼ãƒ—ã‚’ç®¡ç†

```python
import asyncio

def test_async_function():
    loop = asyncio.get_event_loop()  # âŒ æ‰‹å‹•ä½œæˆ
    result = loop.run_until_complete(my_async_function())
    loop.close()  # âŒ æ‰‹å‹•ã‚¯ãƒ­ãƒ¼ã‚º
    assert result == expected
```

#### âœ… OK: pytest-asyncio ã®è‡ªå‹•ç®¡ç†

```python
import pytest

@pytest.mark.asyncio
async def test_async_function():
    result = await my_async_function()
    assert result == expected
```

### pytest-asyncio ã®è¨­å®š

```ini
# pytest.ini
[pytest]
asyncio_mode = auto  # è‡ªå‹•çš„ã« async def test_* ã‚’æ¤œå‡º
```

**`auto` ãƒ¢ãƒ¼ãƒ‰ã®åˆ©ç‚¹**:
- `@pytest.mark.asyncio` ãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿ãŒä¸è¦
- ã‚¤ãƒ™ãƒ³ãƒˆãƒ«ãƒ¼ãƒ—ã®è‡ªå‹•ä½œæˆãƒ»ç ´æ£„
- ãƒ†ã‚¹ãƒˆé–“ã®å®Œå…¨ãªåˆ†é›¢

### éåŒæœŸãƒ•ã‚£ã‚¯ã‚¹ãƒãƒ£ã®ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹

```python
import pytest

# âœ… OK: éåŒæœŸãƒ•ã‚£ã‚¯ã‚¹ãƒãƒ£
@pytest.fixture
async def async_resource():
    resource = await create_resource()
    yield resource
    await resource.cleanup()

# âœ… OK: ä½¿ç”¨ä¾‹
async def test_with_async_fixture(async_resource):
    result = await async_resource.do_something()
    assert result is not None
```

### ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã‚¿ã‚¹ã‚¯ã®é©åˆ‡ãªç®¡ç†

```python
import asyncio
import pytest

# âŒ NG: ã‚¿ã‚¹ã‚¯ã‚’æ”¾ç½®
async def test_background_task():
    task = asyncio.create_task(long_running_operation())
    result = await some_other_operation()
    # task ãŒå®Ÿè¡Œä¸­ã®ã¾ã¾ãƒ†ã‚¹ãƒˆçµ‚äº†

# âœ… OK: ã‚¿ã‚¹ã‚¯ã‚’é©åˆ‡ã«ã‚­ãƒ£ãƒ³ã‚»ãƒ«
async def test_background_task():
    task = asyncio.create_task(long_running_operation())
    try:
        result = await some_other_operation()
    finally:
        task.cancel()
        try:
            await task
        except asyncio.CancelledError:
            pass
```

### ã‚¤ãƒ™ãƒ³ãƒˆãƒ«ãƒ¼ãƒ—ãƒ‡ãƒãƒƒã‚°

```bash
# ã‚¤ãƒ™ãƒ³ãƒˆãƒ«ãƒ¼ãƒ—é–¢é€£ã®ã‚¨ãƒ©ãƒ¼ã‚’è©³ç´°è¡¨ç¤º
pytest tests/test_async.py -v --log-cli-level=DEBUG

# æœªå®Œäº†ã‚¿ã‚¹ã‚¯ã®è­¦å‘Šã‚’æœ‰åŠ¹åŒ–
PYTHONWARNINGS="default" pytest tests/test_async.py -v
```

---

## ãƒ†ã‚¹ãƒˆãƒ¬ã‚¤ãƒ¤ãƒ¼ã¨ãƒãƒ¼ã‚«ãƒ¼

### ç¾åœ¨ã®ãƒãƒ¼ã‚«ãƒ¼åˆ†é¡

| ãƒãƒ¼ã‚«ãƒ¼ | èª¬æ˜ | å®Ÿè¡Œæ¡ä»¶ |
|---------|------|---------|
| `ci_safe` | CIç’°å¢ƒã§å®Ÿè¡Œå¯èƒ½ | ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå®Ÿè¡Œå¯¾è±¡ï¼ˆ1042ãƒ†ã‚¹ãƒˆï¼‰ |
| `local_only` | ãƒ­ãƒ¼ã‚«ãƒ«å°‚ç”¨ï¼ˆé‡ã„æ¤œè¨¼ï¼‰ | `RUN_LOCAL_FINAL_VERIFICATION=1` |
| `integration` | çµ±åˆãƒ†ã‚¹ãƒˆï¼ˆãƒ–ãƒ©ã‚¦ã‚¶ä¾å­˜ï¼‰ | `RUN_LOCAL_INTEGRATION=1` |
| `llm` | LLMæ©Ÿèƒ½ä¾å­˜ | `ENABLE_LLM=true` |
| `git_script_integration` | Git ã‚¹ã‚¯ãƒªãƒ—ãƒˆçµ±åˆ | ãƒªãƒ•ã‚¡ã‚¯ã‚¿å¾…ã¡ï¼ˆ8ãƒ†ã‚¹ãƒˆï¼‰ |

### ãƒãƒ¼ã‚«ãƒ¼ä½¿ç”¨ä¾‹

```python
import pytest

@pytest.mark.ci_safe
def test_basic_functionality():
    """CI ã§å®Ÿè¡Œã•ã‚Œã‚‹åŸºæœ¬ãƒ†ã‚¹ãƒˆ"""
    assert True

@pytest.mark.integration
@pytest.mark.skipif(
    os.getenv("RUN_LOCAL_INTEGRATION") != "1",
    reason="Integration tests require RUN_LOCAL_INTEGRATION=1"
)
def test_browser_integration():
    """ãƒ–ãƒ©ã‚¦ã‚¶çµ±åˆãƒ†ã‚¹ãƒˆ"""
    pass

@pytest.mark.local_only
def test_heavy_verification():
    """é‡ã„æ¤œè¨¼ãƒ†ã‚¹ãƒˆï¼ˆãƒ­ãƒ¼ã‚«ãƒ«å°‚ç”¨ï¼‰"""
    pass
```

### ã‚¹ã‚­ãƒƒãƒ—ã‚«ãƒ†ã‚´ãƒªï¼ˆ31ãƒ†ã‚¹ãƒˆï¼‰

| ã‚«ãƒ†ã‚´ãƒª | æ¦‚æ•° | ç†ç”± | æœ‰åŠ¹åŒ–æ–¹æ³• |
|---------|------|------|-----------|
| LLMä¾å­˜ | 1 | LLMæ©Ÿèƒ½ãŒå¿…è¦ | `ENABLE_LLM=true` |
| local_only | ~10 | é•·æ™‚é–“å®Ÿè¡Œ/ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ– | `RUN_LOCAL_FINAL_VERIFICATION=1` |
| integration | ~12 | ãƒ–ãƒ©ã‚¦ã‚¶/ç’°å¢ƒä¾å­˜ | `RUN_LOCAL_INTEGRATION=1` |
| git_script_integration | 8 | Resolver ãƒªãƒ•ã‚¡ã‚¯ã‚¿å¾…ã¡ | è¨ˆç”»ä¸­ |

### å®Ÿè¡Œä¾‹

```bash
# CI ã‚»ãƒ¼ãƒ•ãƒ†ã‚¹ãƒˆã®ã¿ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰
pytest -m "ci_safe" -v

# çµ±åˆãƒ†ã‚¹ãƒˆã‚‚å«ã‚ã‚‹
RUN_LOCAL_INTEGRATION=1 pytest -m "ci_safe or integration" -v

# ã™ã¹ã¦ã®ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œ
RUN_LOCAL_INTEGRATION=1 RUN_LOCAL_FINAL_VERIFICATION=1 pytest -v

# LLMæ©Ÿèƒ½ä»˜ãã§å®Ÿè¡Œ
ENABLE_LLM=true pytest -m "ci_safe" -v
```

---

## ãƒ—ãƒƒã‚·ãƒ¥å‰æ¤œè¨¼

### å¿…é ˆãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ

```bash
# âœ… 1. ç’°å¢ƒå¤‰æ•°ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
unset BYKILT_ENV

# âœ… 2. æˆæœç‰©ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
./scripts/clean_test_artifacts.sh
./scripts/clean_test_logs.sh

# âœ… 3. CIç’°å¢ƒã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
ENABLE_LLM=true pytest -m "ci_safe" --cov=src --cov-report=term -v

# âœ… 4. ä¿®æ­£ã—ãŸãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿ãƒ†ã‚¹ãƒˆï¼ˆé«˜é€Ÿãƒã‚§ãƒƒã‚¯ï¼‰
pytest tests/path/to/modified_test.py -v

# âœ… 5. ã‚«ãƒãƒ¬ãƒƒã‚¸ç¢ºèª
pytest -m "ci_safe" --cov=src --cov-report=html
open htmlcov/index.html  # ã‚«ãƒãƒ¬ãƒƒã‚¸ãƒ¬ãƒãƒ¼ãƒˆã‚’ç¢ºèª
```

### ãƒ—ãƒƒã‚·ãƒ¥å‰ã®ä¸€èˆ¬çš„ãªå•é¡Œ

#### å•é¡Œ1: ãƒ­ãƒ¼ã‚«ãƒ«ã§æˆåŠŸã€CI ã§å¤±æ•—

**åŸå› **:
- `BYKILT_ENV=dev` ãŒè¨­å®šã•ã‚Œã¦ã„ã‚‹
- å¤ã„æˆæœç‰©ãŒæ®‹ã£ã¦ã„ã‚‹
- ãƒ†ã‚¹ãƒˆå®Ÿè¡Œé †åºãŒç•°ãªã‚‹

**è§£æ±º**:
```bash
unset BYKILT_ENV
./scripts/clean_test_artifacts.sh
./scripts/clean_test_logs.sh
ENABLE_LLM=true pytest -m "ci_safe" -v
```

#### å•é¡Œ2: ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãƒ¬ãƒ™ãƒ«å¤‰æ•°ã®ãƒ¢ãƒƒã‚¯å¤±æ•—

**åŸå› **:
- æ–‡å­—åˆ—ãƒ™ãƒ¼ã‚¹ã® `patch()` ã‚’ä½¿ç”¨
- å¤‰æ•°ãŒã‚¤ãƒ³ãƒãƒ¼ãƒˆæ™‚ã«è©•ä¾¡æ¸ˆã¿

**è§£æ±º**:
```python
# âŒ NG
with patch('module.VARIABLE', False):
    pass

# âœ… OK
import module
with patch.object(module, 'VARIABLE', False):
    pass
```

#### å•é¡Œ3: ã‚¤ãƒ³ãƒ‡ãƒ³ãƒˆã‚¨ãƒ©ãƒ¼ï¼ˆã‚¢ã‚µãƒ¼ã‚·ãƒ§ãƒ³ãŒã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå¤–ï¼‰

**åŸå› **:
- `with` ãƒ–ãƒ­ãƒƒã‚¯ã®å¤–ã§ã‚¢ã‚µãƒ¼ã‚·ãƒ§ãƒ³
- ãƒ¢ãƒƒã‚¯ãŒæ—¢ã«è§£é™¤ã•ã‚Œã¦ã„ã‚‹

**è§£æ±º**:
```python
# âŒ NG
with patch.object(module, 'VARIABLE', False):
    result = function()
assert result == expected  # ãƒ¢ãƒƒã‚¯è§£é™¤æ¸ˆã¿

# âœ… OK
with patch.object(module, 'VARIABLE', False):
    result = function()
    assert result == expected  # ãƒ¢ãƒƒã‚¯æœ‰åŠ¹
```

### å®Ÿè¡Œæ™‚é–“ã®ç›®å®‰

| ãƒ†ã‚¹ãƒˆç¯„å›² | å®Ÿè¡Œæ™‚é–“ï¼ˆç›®å®‰ï¼‰ |
|-----------|----------------|
| å˜ä¸€ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ« | 5-10ç§’ |
| ci_safe å…¨ä½“ï¼ˆ1042ãƒ†ã‚¹ãƒˆï¼‰ | 2-5åˆ† |
| CI å…¨ä½“å®Ÿè¡Œ | 5-8åˆ† |

**æ¨å¥¨**: ãƒ—ãƒƒã‚·ãƒ¥å‰ã«å°‘ãªãã¨ã‚‚ä¿®æ­£ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œ

---

## ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°æ±ºå®šæœ¨

### ã‚¹ãƒ†ãƒƒãƒ—1: ã‚¨ãƒ©ãƒ¼ã®åˆ†é¡

```
ãƒ†ã‚¹ãƒˆå¤±æ•—
â”œâ”€ ãƒ­ãƒ¼ã‚«ãƒ«ã§æˆåŠŸã€CI ã§å¤±æ•—
â”‚  â””â”€ â†’ ç’°å¢ƒå¤‰æ•°ãƒã‚§ãƒƒã‚¯ï¼ˆBYKILT_ENV, ENABLE_LLMï¼‰
â”‚     â””â”€ â†’ æˆæœç‰©ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
â”‚        â””â”€ â†’ ãƒ†ã‚¹ãƒˆé †åºç¢ºèª
â”‚
â”œâ”€ ãƒ­ãƒ¼ã‚«ãƒ«ã§ã‚‚å¤±æ•—
â”‚  â”œâ”€ ImportError / ModuleNotFoundError
â”‚  â”‚  â””â”€ â†’ ENABLE_LLM ç¢ºèª
â”‚  â”‚     â””â”€ â†’ ä¾å­˜é–¢ä¿‚ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ç¢ºèª
â”‚  â”‚
â”‚  â”œâ”€ RuntimeError (event loop)
â”‚  â”‚  â””â”€ â†’ ã‚¤ãƒ™ãƒ³ãƒˆãƒ«ãƒ¼ãƒ—ç®¡ç†ç¢ºèª
â”‚  â”‚     â””â”€ â†’ pytest-asyncio è¨­å®šç¢ºèª
â”‚  â”‚
â”‚  â”œâ”€ AssertionError
â”‚  â”‚  â””â”€ â†’ ãƒ¢ãƒƒã‚¯ã‚¹ã‚³ãƒ¼ãƒ—ç¢ºèª
â”‚  â”‚     â””â”€ â†’ ã‚¤ãƒ³ãƒ‡ãƒ³ãƒˆç¢ºèª
â”‚  â”‚
â”‚  â””â”€ FileNotFoundError / ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªé–¢é€£
â”‚     â””â”€ â†’ æˆæœç‰©ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
â”‚        â””â”€ â†’ tmp_path ä½¿ç”¨ç¢ºèª
â”‚
â””â”€ é–“æ¬ çš„å¤±æ•—
   â””â”€ â†’ ãƒ†ã‚¹ãƒˆé †åºä¾å­˜ç¢ºèª
      â””â”€ â†’ pytest-randomly ã§ãƒ©ãƒ³ãƒ€ãƒ å®Ÿè¡Œ
         â””â”€ â†’ ãƒ•ã‚£ã‚¯ã‚¹ãƒãƒ£ã‚¹ã‚³ãƒ¼ãƒ—ç¢ºèª
```

### ã‚¹ãƒ†ãƒƒãƒ—2: è¨ºæ–­ã‚³ãƒãƒ³ãƒ‰

```bash
# 1. ç’°å¢ƒå¤‰æ•°ã®ç¢ºèª
env | grep -E "BYKILT|ENABLE_LLM|RUN_LOCAL"

# 2. æˆæœç‰©ã®ç¢ºèª
ls -la artifacts/runs/
ls -la .pytest_cache/

# 3. å˜ä½“å®Ÿè¡Œã§å•é¡Œã‚’åˆ‡ã‚Šåˆ†ã‘
pytest tests/path/to/test_file.py::test_specific -xvs

# 4. ãƒ†ã‚¹ãƒˆé †åºã®å½±éŸ¿ã‚’ç¢ºèª
pytest tests/path/to/test_file.py -v  # å…¨ä½“
pytest tests/path/to/test_file.py::test_specific -v  # å˜ä½“

# 5. ãƒ¢ãƒƒã‚¯ã®çŠ¶æ…‹ã‚’ç¢ºèª
pytest tests/path/to/test_file.py -v --log-cli-level=DEBUG

# 6. ã‚«ãƒãƒ¬ãƒƒã‚¸ã§å®Ÿè¡Œãƒ‘ã‚¹ã‚’ç¢ºèª
pytest tests/path/to/test_file.py --cov=src --cov-report=term-missing -v
```

### ã‚¹ãƒ†ãƒƒãƒ—3: ã‚ˆãã‚ã‚‹è§£æ±ºãƒ‘ã‚¿ãƒ¼ãƒ³

#### ãƒ‘ã‚¿ãƒ¼ãƒ³1: ç’°å¢ƒå¤‰æ•°ãƒªã‚»ãƒƒãƒˆ

```bash
# ã™ã¹ã¦ã®ç’°å¢ƒå¤‰æ•°ã‚’ã‚¯ãƒªã‚¢
unset BYKILT_ENV
unset RUN_LOCAL_INTEGRATION
unset RUN_LOCAL_FINAL_VERIFICATION

# CIç’°å¢ƒã‚’å†ç¾
export ENABLE_LLM=true
pytest -m "ci_safe" -v
```

#### ãƒ‘ã‚¿ãƒ¼ãƒ³2: å®Œå…¨ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—

```bash
# ã™ã¹ã¦ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
./scripts/clean_test_artifacts.sh
./scripts/clean_test_logs.sh
rm -rf artifacts/runs/*
rm -rf .pytest_cache/

# å†å®Ÿè¡Œ
pytest -m "ci_safe" -v
```

#### ãƒ‘ã‚¿ãƒ¼ãƒ³3: ä¾å­˜é–¢ä¿‚ã®å†ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«

```bash
# ä»®æƒ³ç’°å¢ƒã®å†ä½œæˆ
deactivate
rm -rf venv
python3 -m venv venv
source venv/bin/activate
pip install -r requirements-dev.txt
```

---

## ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹

### 1. ãƒ†ã‚¹ãƒˆä½œæˆæ™‚ã®ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ

- [ ] `tmp_path` ã‚’ä½¿ç”¨ã—ã¦ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆã‚’åˆ†é›¢
- [ ] ãƒ¢ãƒƒã‚¯ã¯ `with` ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå†…ã§ã‚¢ã‚µãƒ¼ã‚·ãƒ§ãƒ³
- [ ] ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãƒ¬ãƒ™ãƒ«å¤‰æ•°ã¯ `patch.object()` ã‚’ä½¿ç”¨
- [ ] éåŒæœŸãƒ†ã‚¹ãƒˆã¯ `async def` + pytest-asyncio
- [ ] ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã‚¿ã‚¹ã‚¯ã¯ `finally` ã§ã‚­ãƒ£ãƒ³ã‚»ãƒ«
- [ ] ãƒ•ã‚£ã‚¯ã‚¹ãƒãƒ£ã‚¹ã‚³ãƒ¼ãƒ—ã¯æœ€å°é™ï¼ˆ`function`ï¼‰
- [ ] é©åˆ‡ãªãƒãƒ¼ã‚«ãƒ¼ï¼ˆ`ci_safe`, `integration` ãªã©ï¼‰ã‚’è¨­å®š

### 2. ãƒ—ãƒƒã‚·ãƒ¥å‰ã®ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ

- [ ] `unset BYKILT_ENV` ã§ç’°å¢ƒå¤‰æ•°ã‚’ã‚¯ãƒªã‚¢
- [ ] `./scripts/clean_test_artifacts.sh` ã§æˆæœç‰©ã‚’å‰Šé™¤
- [ ] `./scripts/clean_test_logs.sh` ã§ãƒ­ã‚°ã‚’ã‚¯ãƒªã‚¢
- [ ] `ENABLE_LLM=true pytest -m "ci_safe" -v` ã§ CI ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
- [ ] ä¿®æ­£ã—ãŸãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’å€‹åˆ¥ã«å®Ÿè¡Œã—ã¦ç¢ºèª
- [ ] ã‚«ãƒãƒ¬ãƒƒã‚¸ãŒ 65% ä»¥ä¸Šã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèª

### 3. CIå¤±æ•—æ™‚ã®å¯¾å¿œãƒ•ãƒ­ãƒ¼

1. **ãƒ­ãƒ¼ã‚«ãƒ«ã§ã®å†ç¾**:
   ```bash
   unset BYKILT_ENV
   ENABLE_LLM=true pytest -m "ci_safe" -v
   ```

2. **å¤±æ•—ãƒ†ã‚¹ãƒˆã®åˆ‡ã‚Šåˆ†ã‘**:
   ```bash
   pytest tests/path/to/failing_test.py::test_name -xvs
   ```

3. **ãƒ¢ãƒƒã‚¯ã¨ã‚¤ãƒ³ãƒ‡ãƒ³ãƒˆã®ç¢ºèª**:
   - ã™ã¹ã¦ã®ã‚¢ã‚µãƒ¼ã‚·ãƒ§ãƒ³ãŒ `with` ãƒ–ãƒ­ãƒƒã‚¯å†…ã«ã‚ã‚‹ã‹
   - `patch.object()` ã‚’ä½¿ç”¨ã—ã¦ã„ã‚‹ã‹

4. **æˆæœç‰©ã®å½±éŸ¿ç¢ºèª**:
   ```bash
   ./scripts/clean_test_artifacts.sh
   pytest tests/path/to/failing_test.py -v
   ```

5. **ä¿®æ­£ã¨ã‚³ãƒŸãƒƒãƒˆ**:
   ```bash
   git add tests/path/to/failing_test.py
   git commit -m "fix: correct test isolation issue"
   git push
   ```

### 4. ã‚³ãƒ¼ãƒ‰ãƒ¬ãƒ“ãƒ¥ãƒ¼æ™‚ã®ç¢ºèªãƒã‚¤ãƒ³ãƒˆ

- [ ] ãƒ†ã‚¹ãƒˆã¯ CI ç’°å¢ƒã§å®Ÿè¡Œå¯èƒ½ã‹ï¼ˆ`ci_safe` ãƒãƒ¼ã‚«ãƒ¼ï¼‰
- [ ] `tmp_path` ã‚’ä½¿ç”¨ã—ã¦ã„ã‚‹ã‹
- [ ] ãƒ¢ãƒƒã‚¯ã®ã‚¹ã‚³ãƒ¼ãƒ—ã¯é©åˆ‡ã‹
- [ ] éåŒæœŸãƒ†ã‚¹ãƒˆã®ã‚¤ãƒ™ãƒ³ãƒˆãƒ«ãƒ¼ãƒ—ç®¡ç†ã¯é©åˆ‡ã‹
- [ ] ãƒ†ã‚¹ãƒˆé †åºã«ä¾å­˜ã—ã¦ã„ãªã„ã‹
- [ ] ç’°å¢ƒå¤‰æ•°ã®ä¾å­˜ã¯æ˜ç¤ºã•ã‚Œã¦ã„ã‚‹ã‹

---

## é–¢é€£ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ

- **Issue #340**: ãƒ†ã‚¹ãƒˆã‚«ãƒãƒ¬ãƒƒã‚¸ 20% â†’ 65% ã¸ã®æ”¹å–„
- **Issue #263**: ã‚¤ãƒ™ãƒ³ãƒˆãƒ«ãƒ¼ãƒ—å®‰å®šåŒ–
- **Issue #101**: éŒ²ç”»æ©Ÿèƒ½ã®å®‰å®šæ€§
- **Issue #81**: ãƒ†ã‚¹ãƒˆãƒãƒ¼ã‚«ãƒ¼ã®å½¢å¼åŒ–
- **Issue #272**: Feature Flag Admin UI

- **ã‚¹ã‚¯ãƒªãƒ—ãƒˆ**:
  - `scripts/clean_test_artifacts.sh` - æˆæœç‰©ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
  - `scripts/clean_test_logs.sh` - ãƒ­ã‚°ã¨ã‚«ãƒãƒ¬ãƒƒã‚¸ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—

- **è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«**:
  - `pytest.ini` - pytest è¨­å®šï¼ˆasyncio_mode = autoï¼‰
  - `pyproject.toml` - ã‚«ãƒãƒ¬ãƒƒã‚¸è¨­å®š
  - `.github/copilot-instructions.md` - ãƒ—ãƒƒã‚·ãƒ¥å‰æ¤œè¨¼ãƒ«ãƒ¼ãƒ«

---

## ã¾ã¨ã‚

ã“ã®ã‚¬ã‚¤ãƒ‰ã¯ã€2bykilt ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§ã®ãƒ†ã‚¹ãƒˆå®Ÿè¡Œã«ãŠã‘ã‚‹åŒ…æ‹¬çš„ãªçŸ¥è­˜ã‚’æä¾›ã—ã¾ã™ã€‚

**é‡è¦ãªãƒã‚¤ãƒ³ãƒˆ**:
1. âœ… ãƒ—ãƒƒã‚·ãƒ¥å‰ã«ã¯å¿…ãš `unset BYKILT_ENV` ã¨æˆæœç‰©ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚’å®Ÿè¡Œ
2. âœ… ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãƒ¬ãƒ™ãƒ«å¤‰æ•°ã¯ `patch.object()` ã§ãƒ¢ãƒƒã‚¯
3. âœ… ã™ã¹ã¦ã®ã‚¢ã‚µãƒ¼ã‚·ãƒ§ãƒ³ã¯ `with` ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå†…ã§å®Ÿè¡Œ
4. âœ… éåŒæœŸãƒ†ã‚¹ãƒˆã¯ pytest-asyncio ã«ä»»ã›ã‚‹
5. âœ… ãƒ†ã‚¹ãƒˆåˆ†é›¢ã®ãŸã‚ `tmp_path` ã‚’ä½¿ç”¨

**æœ€çµ‚ãƒã‚§ãƒƒã‚¯**:
```bash
unset BYKILT_ENV
./scripts/clean_test_artifacts.sh
./scripts/clean_test_logs.sh
ENABLE_LLM=true pytest -m "ci_safe" --cov=src --cov-report=term -v
```

ã“ã®ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã«å¾“ã†ã“ã¨ã§ã€ãƒ­ãƒ¼ã‚«ãƒ«ã¨ CI ã®ä¸¡æ–¹ã§å®‰å®šã—ãŸãƒ†ã‚¹ãƒˆå®Ÿè¡ŒãŒå¯èƒ½ã«ãªã‚Šã¾ã™ã€‚
