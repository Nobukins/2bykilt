#!/usr/bin/env python3
"""
æœ€å°æ§‹æˆï¼ˆLLMç„¡åŠ¹ï¼‰ã§ã®æ©Ÿèƒ½æ¤œè¨¼ãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆ
venv312ç’°å¢ƒã§ã®LLMé–¢é€£ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãªã—ã§ã®å‹•ä½œç¢ºèª
"""

import os
import sys
import asyncio
import subprocess
import tempfile
import time
from pathlib import Path

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’è¨­å®š
PROJECT_DIR = Path(__file__).parent.absolute()
sys.path.insert(0, str(PROJECT_DIR))

class MinimalConfigTest:
    def __init__(self):
        self.results = []
        self.python_exec = self._detect_python_exec()

    def _detect_python_exec(self) -> str:
        """Attempt to locate a project python (prefer venv/venv312) else fallback to current interpreter."""
        candidates = [
            PROJECT_DIR / 'venv' / 'bin' / 'python',
            PROJECT_DIR / 'venv312' / 'bin' / 'python',
            PROJECT_DIR.parent / 'venv' / 'bin' / 'python',
            PROJECT_DIR.parent / 'venv312' / 'bin' / 'python',
        ]
        for c in candidates:
            if c.exists():
                return str(c)
        return sys.executable
        
    def log_result(self, test_name, success, message):
        status = "âœ… PASS" if success else "âŒ FAIL"
        result = f"{status}: {test_name} - {message}"
        print(result)
        self.results.append((test_name, success, message))
        
    def test_minimal_imports(self):
        """æœ€å°æ§‹æˆã§ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚¤ãƒ³ãƒãƒ¼ãƒˆãƒ†ã‚¹ãƒˆ"""
        try:
            env = os.environ.copy()
            env['ENABLE_LLM'] = 'false'
            
            test_code = '''
import sys
import os
os.environ["ENABLE_LLM"] = "false"

print("Starting minimal import test...")

# Test basic Python modules
try:
    import json
    import asyncio
    import subprocess
    from pathlib import Path
    print("âœ… Basic Python modules imported")
except Exception as e:
    print(f"âŒ Basic Python modules failed: {e}")
    sys.exit(1)

# Test third-party dependencies
try:
    import gradio as gr
    print("âœ… Gradio imported")
except Exception as e:
    print(f"âŒ Gradio import failed: {e}")
    sys.exit(1)

try:
    from playwright.async_api import async_playwright
    print("âœ… Playwright imported")
except Exception as e:
    print(f"âŒ Playwright import failed: {e}")
    sys.exit(1)

try:
    import pandas as pd
    import numpy as np
    print("âœ… Data processing modules imported")
except Exception as e:
    print(f"âŒ Data processing modules failed: {e}")
    sys.exit(1)

# Test project modules
try:
    from src.utils import utils
    print("âœ… Utils module imported")
except Exception as e:
    print(f"âŒ Utils module failed: {e}")
    sys.exit(1)

try:
    from src.browser.browser_manager import initialize_browser
    from src.browser.browser_config import BrowserConfig
    print("âœ… Browser modules imported")
except Exception as e:
    print(f"âŒ Browser modules failed: {e}")
    sys.exit(1)

try:
    from src.config.standalone_prompt_evaluator import (
        pre_evaluate_prompt_standalone,
        extract_params_standalone,
        resolve_sensitive_env_variables_standalone
    )
    print("âœ… Standalone prompt evaluator imported")
except Exception as e:
    print(f"âŒ Standalone prompt evaluator failed: {e}")
    sys.exit(1)

print("SUCCESS: All minimal configuration modules imported successfully")
'''
            
            result = subprocess.run(
                [self.python_exec, '-c', test_code],
                cwd=PROJECT_DIR,
                env=env,
                capture_output=True,
                text=True,
                timeout=60
            )
            
            if result.returncode == 0 and "SUCCESS" in result.stdout:
                self.log_result("æœ€å°æ§‹æˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚¤ãƒ³ãƒãƒ¼ãƒˆ", True, "ã™ã¹ã¦ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒæ­£å¸¸ã«ã‚¤ãƒ³ãƒãƒ¼ãƒˆ")
            else:
                self.log_result("æœ€å°æ§‹æˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚¤ãƒ³ãƒãƒ¼ãƒˆ", False, f"ã‚¨ãƒ©ãƒ¼: {result.stderr[:200]}")
                
        except Exception as e:
            self.log_result("æœ€å°æ§‹æˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚¤ãƒ³ãƒãƒ¼ãƒˆ", False, str(e))
    
    def test_llm_modules_not_available(self):
        """LLMé–¢é€£ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒåˆ©ç”¨ä¸å¯ã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèª"""
        try:
            env = os.environ.copy()
            env['ENABLE_LLM'] = 'false'
            
            test_code = '''
import sys
import os
os.environ["ENABLE_LLM"] = "false"

# Test that LLM modules are not available or properly handled
llm_modules_to_test = [
    ("anthropic", "anthropic"),
    ("openai", "openai"),
    ("langchain", "langchain"),
    ("browser_use", "browser_use"),
]

missing_modules = []
for module_name, import_name in llm_modules_to_test:
    try:
        __import__(import_name)
        print(f"âš ï¸ {module_name} is available (unexpected in minimal config)")
    except ImportError:
        missing_modules.append(module_name)
        print(f"âœ… {module_name} not available (expected in minimal config)")

if len(missing_modules) >= 3:  # Most LLM modules should be missing
    print("SUCCESS: LLM modules are properly unavailable in minimal config")
else:
    print("WARNING: Some LLM modules are available in minimal config")
'''
            
            result = subprocess.run(
                [self.python_exec, '-c', test_code],
                cwd=PROJECT_DIR,
                env=env,
                capture_output=True,
                text=True,
                timeout=30
            )
            
            if result.returncode == 0 and ("SUCCESS" in result.stdout or "WARNING" in result.stdout):
                self.log_result("LLMãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«éåˆ©ç”¨ç¢ºèª", True, "LLMé–¢é€£ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒé©åˆ‡ã«åˆ¶é™ã•ã‚Œã¦ã„ã‚‹")
            else:
                self.log_result("LLMãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«éåˆ©ç”¨ç¢ºèª", False, f"ã‚¨ãƒ©ãƒ¼: {result.stderr[:200]}")
                
        except Exception as e:
            self.log_result("LLMãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«éåˆ©ç”¨ç¢ºèª", False, str(e))
    
    def test_minimal_app_startup(self):
        """æœ€å°æ§‹æˆã§ã®ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³èµ·å‹•ãƒ†ã‚¹ãƒˆ"""
        try:
            env = os.environ.copy()
            env['ENABLE_LLM'] = 'false'
            
            # Test help command
            bykilt_path = Path(__file__).resolve().parents[2] / 'bykilt.py'
            cmd = [self.python_exec, str(bykilt_path), '--help'] if bykilt_path.exists() else [self.python_exec, '-m', 'bykilt', '--help']
            result = subprocess.run(
                cmd,
                cwd=Path(__file__).resolve().parents[2],
                env=env,
                capture_output=True,
                text=True,
                timeout=60
            )
            
            if result.returncode == 0 and "Gradio UI for 2Bykilt Agent" in result.stdout:
                self.log_result("æœ€å°æ§‹æˆã‚¢ãƒ—ãƒªèµ·å‹•", True, "ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãŒæ­£å¸¸ã«èµ·å‹•ãƒ»ãƒ˜ãƒ«ãƒ—è¡¨ç¤º")
                
                # Check for LLM disabled message
                if "LLM functionality is disabled" in result.stdout or "ENABLE_LLM=false" in result.stdout:
                    print("  âœ… LLMç„¡åŠ¹ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒæ­£å¸¸ã«è¡¨ç¤º")
                else:
                    print("  âš ï¸ LLMç„¡åŠ¹ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒè¡¨ç¤ºã•ã‚Œã¦ã„ãªã„")
            else:
                self.log_result("æœ€å°æ§‹æˆã‚¢ãƒ—ãƒªèµ·å‹•", False, f"ã‚¨ãƒ©ãƒ¼: {result.stderr[:200]}")
                
        except Exception as e:
            self.log_result("æœ€å°æ§‹æˆã‚¢ãƒ—ãƒªèµ·å‹•", False, str(e))
    
    def test_minimal_browser_functionality(self):
        """æœ€å°æ§‹æˆã§ã®ãƒ–ãƒ©ã‚¦ã‚¶æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ"""
        try:
            env = os.environ.copy()
            env['ENABLE_LLM'] = 'false'
            
            test_code = '''
import os
import asyncio
os.environ["ENABLE_LLM"] = "false"

from playwright.async_api import async_playwright
from src.browser.browser_config import BrowserConfig

async def test_minimal_browser():
    try:
        print("Testing minimal browser functionality...")
        
        # Test browser config
        config = BrowserConfig()
        print(f"âœ… Browser config created: {type(config)}")
        
        # Test direct Playwright
        async with async_playwright() as p:
            browser = await p.chromium.launch(headless=True)
            print("âœ… Browser launched")
            
            page = await browser.new_page()
            print("âœ… New page created")
            
            await page.goto("https://nogtips.wordpress.com/2025/03/31/llms-txt%e3%81%ab%e3%81%a4%e3%81%84%e3%81%a6/")
            print("âœ… Page navigation successful")
            
            title = await page.title()
            print(f"âœ… Page title retrieved: {title[:50]}")
            
            content = await page.content()
            if "httpbin" in content:
                print("âœ… Page content verification successful")
            else:
                print("âŒ Page content verification failed")
                return False
            
            await browser.close()
            print("âœ… Browser closed successfully")
            
        print("SUCCESS: All minimal browser tests passed")
        return True
        
    except Exception as e:
        print(f"âŒ Browser test failed: {e}")
        return False

result = asyncio.run(test_minimal_browser())
if not result:
    exit(1)
'''
            
            result = subprocess.run(
                [self.python_exec, '-c', test_code],
                cwd=PROJECT_DIR,
                env=env,
                capture_output=True,
                text=True,
                timeout=90
            )
            
            if result.returncode == 0 and "SUCCESS" in result.stdout:
                self.log_result("æœ€å°æ§‹æˆãƒ–ãƒ©ã‚¦ã‚¶æ©Ÿèƒ½", True, "ãƒ–ãƒ©ã‚¦ã‚¶æ©Ÿèƒ½ãŒæ­£å¸¸ã«å‹•ä½œ")
            else:
                self.log_result("æœ€å°æ§‹æˆãƒ–ãƒ©ã‚¦ã‚¶æ©Ÿèƒ½", False, f"ã‚¨ãƒ©ãƒ¼: {result.stderr[:200]}")
                
        except Exception as e:
            self.log_result("æœ€å°æ§‹æˆãƒ–ãƒ©ã‚¦ã‚¶æ©Ÿèƒ½", False, str(e))
    
    def test_minimal_prompt_evaluator(self):
        """æœ€å°æ§‹æˆã§ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè©•ä¾¡å™¨ãƒ†ã‚¹ãƒˆ"""
        try:
            env = os.environ.copy()
            env['ENABLE_LLM'] = 'false'
            
            test_code = '''
import os
os.environ["ENABLE_LLM"] = "false"

from src.config.standalone_prompt_evaluator import (
    pre_evaluate_prompt_standalone,
    extract_params_standalone,
    resolve_sensitive_env_variables_standalone
)

# Test prompt evaluation
test_prompts = [
    "navigate to https://example.com",
    "click button",
    "fill form field",
    "@test_command with parameters"
]

print("Testing standalone prompt evaluator...")

for prompt in test_prompts:
    try:
        result = pre_evaluate_prompt_standalone(prompt)
        print(f"âœ… Prompt '{prompt[:30]}...' evaluated: {type(result)}")
    except Exception as e:
        print(f"âŒ Prompt evaluation failed for '{prompt}': {e}")
        exit(1)

# Test parameter extraction
try:
    params = {"url": "https://example.com", "text": "test"}
    result = extract_params_standalone("Navigate to ${url}", params)
    print(f"âœ… Parameter extraction successful: {type(result)}")
except Exception as e:
    print(f"âŒ Parameter extraction failed: {e}")
    exit(1)

# Test environment variable resolution
try:
    result = resolve_sensitive_env_variables_standalone("Test ${HOME} variable")
    print(f"âœ… Environment variable resolution successful: {type(result)}")
except Exception as e:
    print(f"âŒ Environment variable resolution failed: {e}")
    exit(1)

print("SUCCESS: All standalone prompt evaluator tests passed")
'''
            
            result = subprocess.run(
                [self.python_exec, '-c', test_code],
                cwd=PROJECT_DIR,
                env=env,
                capture_output=True,
                text=True,
                timeout=30
            )
            
            if result.returncode == 0 and "SUCCESS" in result.stdout:
                self.log_result("æœ€å°æ§‹æˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè©•ä¾¡å™¨", True, "ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè©•ä¾¡å™¨ãŒæ­£å¸¸ã«å‹•ä½œ")
            else:
                self.log_result("æœ€å°æ§‹æˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè©•ä¾¡å™¨", False, f"ã‚¨ãƒ©ãƒ¼: {result.stderr[:200]}")
                
        except Exception as e:
            self.log_result("æœ€å°æ§‹æˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè©•ä¾¡å™¨", False, str(e))
    
    def test_minimal_configuration_settings(self):
        """æœ€å°æ§‹æˆã§ã®è¨­å®šç®¡ç†ãƒ†ã‚¹ãƒˆ"""
        try:
            env = os.environ.copy()
            env['ENABLE_LLM'] = 'false'
            
            test_code = '''
import os
import tempfile
from pathlib import Path
os.environ["ENABLE_LLM"] = "false"

from src.utils.default_config_settings import default_config

# Test default config creation
try:
    config = default_config()
    print(f"âœ… Default config created with {len(config)} keys")
    
    # Check for essential keys
    essential_keys = ["browser_config", "recording_config", "ui_config"]
    for key in essential_keys:
        if key in config:
            print(f"âœ… Essential config key '{key}' found")
        else:
            print(f"âš ï¸ Essential config key '{key}' missing")
    
    print("SUCCESS: Configuration management test passed")
    
except Exception as e:
    print(f"âŒ Configuration test failed: {e}")
    exit(1)
'''
            
            result = subprocess.run(
                [self.python_exec, '-c', test_code],
                cwd=PROJECT_DIR,
                env=env,
                capture_output=True,
                text=True,
                timeout=30
            )
            
            if result.returncode == 0 and "SUCCESS" in result.stdout:
                self.log_result("æœ€å°æ§‹æˆè¨­å®šç®¡ç†", True, "è¨­å®šç®¡ç†æ©Ÿèƒ½ãŒæ­£å¸¸ã«å‹•ä½œ")
            else:
                self.log_result("æœ€å°æ§‹æˆè¨­å®šç®¡ç†", False, f"ã‚¨ãƒ©ãƒ¼: {result.stderr[:200]}")
                
        except Exception as e:
            self.log_result("æœ€å°æ§‹æˆè¨­å®šç®¡ç†", False, str(e))
    
    def run_all_tests(self):
        """å…¨æœ€å°æ§‹æˆãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œ"""
        print("=" * 70)
        print("æœ€å°æ§‹æˆï¼ˆLLMç„¡åŠ¹ï¼‰æ©Ÿèƒ½æ¤œè¨¼ãƒ†ã‚¹ãƒˆé–‹å§‹ - venv312ç’°å¢ƒ")
        print("=" * 70)
        
        tests = [
            self.test_minimal_imports,
            self.test_llm_modules_not_available,
            self.test_minimal_app_startup,
            self.test_minimal_browser_functionality,
            self.test_minimal_prompt_evaluator,
            self.test_minimal_configuration_settings,
        ]
        
        for test in tests:
            try:
                test()
                print()  # ç©ºè¡Œã§åŒºåˆ‡ã‚Š
            except Exception as e:
                test_name = test.__name__
                self.log_result(test_name, False, f"ãƒ†ã‚¹ãƒˆå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
        
        print("=" * 70)
        print("æœ€å°æ§‹æˆãƒ†ã‚¹ãƒˆçµæœã‚µãƒãƒªãƒ¼")
        print("=" * 70)
        
        passed = sum(1 for _, success, _ in self.results if success)
        total = len(self.results)
        
        for test_name, success, message in self.results:
            status = "âœ…" if success else "âŒ"
            print(f"{status} {test_name}: {message}")
        
        print(f"\né€šé: {passed}/{total} ãƒ†ã‚¹ãƒˆ")
        
        if passed == total:
            print("ğŸ‰ å…¨æœ€å°æ§‹æˆãƒ†ã‚¹ãƒˆãŒé€šéã—ã¾ã—ãŸï¼LLMç„¡åŠ¹ãƒ¢ãƒ¼ãƒ‰ã¯å®Œå…¨ã«å‹•ä½œã—ã¾ã™ã€‚")
            return True
        else:
            print("âš ï¸ ä¸€éƒ¨ã®æœ€å°æ§‹æˆãƒ†ã‚¹ãƒˆãŒå¤±æ•—ã—ã¾ã—ãŸã€‚è©³ç´°ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
            return False

if __name__ == "__main__":
    tester = MinimalConfigTest()
    success = tester.run_all_tests()
    sys.exit(0 if success else 1)
